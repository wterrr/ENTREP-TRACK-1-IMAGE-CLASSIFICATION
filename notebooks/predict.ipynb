{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwX_LskXSMKi"
      },
      "source": [
        "# Predict Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ezx072GSHyH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBFmoqwdSR0p"
      },
      "outputs": [],
      "source": [
        "class TestPredictor:\n",
        "    def __init__(self, model_dir, device='cuda'):\n",
        "        self.model_dir = Path(model_dir)\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.class_names = [\n",
        "            \"nose-right\", \"nose-left\", \"ear-right\",\n",
        "            \"ear-left\", \"vc-open\", \"vc-closed\", \"throat\"\n",
        "        ]\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "    def load_ensemble_models(self):\n",
        "        print(\"Loading ensemble models...\")\n",
        "\n",
        "        with open(self.model_dir / 'ensemble_info.pkl', 'rb') as f:\n",
        "            ensemble_info = pickle.load(f)\n",
        "\n",
        "        models = []\n",
        "        model_names = ensemble_info['models']\n",
        "        weights = ensemble_info['weights']\n",
        "\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            print(f\"Loading model {i+1}/{len(model_names)}: {model_name}\")\n",
        "\n",
        "            base_name = \"convnext_base.fb_in22k_ft_in1k\"\n",
        "\n",
        "            model = timm.create_model(base_name, pretrained=False, num_classes=self.num_classes)\n",
        "            state_dict = torch.load(self.model_dir / f\"ensemble_model_{i}.pt\", map_location=self.device)\n",
        "            model.load_state_dict(state_dict)\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "\n",
        "            models.append({'model': model, 'weight': weights[i], 'name': model_name})\n",
        "\n",
        "        print(f\"Loaded {len(models)} models successfully.\")\n",
        "        return models\n",
        "\n",
        "    def load_test_data(self, csv_path, img_dir):\n",
        "        test_files = []\n",
        "        with open(csv_path, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                if row:\n",
        "                    img_name = row[0].strip()\n",
        "                    img_path = Path(img_dir) / img_name\n",
        "                    if img_path.exists():\n",
        "                        test_files.append(str(img_path))\n",
        "                    else:\n",
        "                        print(f\"Warning: Image not found: {img_path}\")\n",
        "\n",
        "        print(f\"Loaded {len(test_files)} test images.\")\n",
        "        return test_files\n",
        "\n",
        "    def get_tta_transforms(self, img_size=224, n_aug=5):\n",
        "        class ResizeOrPad:\n",
        "            def __init__(self, min_size):\n",
        "                self.min_size = min_size\n",
        "\n",
        "            def __call__(self, img):\n",
        "                w, h = img.size\n",
        "                if w < self.min_size or h < self.min_size:\n",
        "                    scale = self.min_size / min(w, h)\n",
        "                    new_w = int(w * scale)\n",
        "                    new_h = int(h * scale)\n",
        "                    return T.functional.resize(img, (new_h, new_w))\n",
        "                return img\n",
        "\n",
        "        transforms = [\n",
        "            T.Compose([\n",
        "                ResizeOrPad(img_size),\n",
        "                T.Resize((img_size, img_size)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ]\n",
        "\n",
        "        import random\n",
        "        for i in range(n_aug - 1):\n",
        "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
        "            target_size = max(img_size, img_size + resize_delta)\n",
        "\n",
        "            transforms.append(\n",
        "                T.Compose([\n",
        "                    ResizeOrPad(target_size + 20),\n",
        "                    T.Resize((target_size + 10, target_size + 10)),\n",
        "                    T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
        "                    T.RandomApply([\n",
        "                        T.ColorJitter(\n",
        "                            brightness=random.uniform(0.1, 0.2),\n",
        "                            contrast=random.uniform(0.1, 0.2),\n",
        "                            saturation=random.uniform(0.05, 0.15),\n",
        "                            hue=random.uniform(0.02, 0.05)\n",
        "                        )\n",
        "                    ], p=0.8),\n",
        "                    T.RandomChoice([\n",
        "                        T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
        "                        nn.Identity()\n",
        "                    ]),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "            )\n",
        "        return transforms\n",
        "\n",
        "    def predict_single_image_tta(self, model, img_path, n_aug=5):\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        tta_transforms = self.get_tta_transforms(n_aug=n_aug)\n",
        "\n",
        "        aug_probs = []\n",
        "        with torch.no_grad():\n",
        "            for transform in tta_transforms:\n",
        "                img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                output = model(img_tensor)\n",
        "                probs = F.softmax(output, dim=1)\n",
        "                aug_probs.append(probs)\n",
        "\n",
        "        weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
        "        weights = weights / weights.sum()\n",
        "\n",
        "        final_probs = torch.zeros_like(aug_probs[0])\n",
        "        for i, probs in enumerate(aug_probs):\n",
        "            final_probs += probs * weights[i]\n",
        "\n",
        "        return final_probs.cpu().numpy().squeeze()\n",
        "\n",
        "    def ensemble_predict_batch(self, models, test_files, use_tta=True, batch_size=32):\n",
        "        predictions = {}\n",
        "        for img_path in tqdm(test_files, desc=\"Predicting\"):\n",
        "            img_name = Path(img_path).name\n",
        "            all_model_probs = []\n",
        "            model_weights = []\n",
        "\n",
        "            for model_info in models:\n",
        "                model = model_info['model']\n",
        "                weight = model_info['weight']\n",
        "\n",
        "                if use_tta:\n",
        "                    probs = self.predict_single_image_tta(model, img_path, n_aug=3)\n",
        "                else:\n",
        "                    transform = T.Compose([\n",
        "                        T.Resize((224, 224)),\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "                    ])\n",
        "                    image = Image.open(img_path).convert('RGB')\n",
        "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        probs = F.softmax(output, dim=1).cpu().numpy().squeeze()\n",
        "\n",
        "                all_model_probs.append(probs)\n",
        "                model_weights.append(weight ** 2)\n",
        "\n",
        "            model_weights = np.array(model_weights)\n",
        "            model_weights /= model_weights.sum()\n",
        "\n",
        "            final_probs = np.zeros_like(all_model_probs[0])\n",
        "            for i, probs in enumerate(all_model_probs):\n",
        "                final_probs += probs * model_weights[i]\n",
        "\n",
        "            pred_class = np.argmax(final_probs)\n",
        "            predictions[img_name] = int(pred_class)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def predict_and_save(self, csv_path, img_dir, output_path, use_tta=True):\n",
        "        models = self.load_ensemble_models()\n",
        "        test_files = self.load_test_data(csv_path, img_dir)\n",
        "\n",
        "        print(\"\\nStarting prediction...\")\n",
        "        predictions = self.ensemble_predict_batch(models, test_files, use_tta=use_tta)\n",
        "\n",
        "        print(f\"\\nSaving results to {output_path}\")\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(predictions, f, indent=2)\n",
        "\n",
        "        print(f\"Saved {len(predictions)} predictions\")\n",
        "\n",
        "        print(\"\\nSample predictions:\")\n",
        "        for i, (img_name, pred) in enumerate(list(predictions.items())[:5]):\n",
        "            print(f\"  {img_name}: {pred} ({self.class_names[pred]})\")\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46tppNu1SdmJ"
      },
      "outputs": [],
      "source": [
        "model_dir = \"/kaggle/input/convnextbase-ensemble-metalearner\"\n",
        "csv_path = \"//kaggle/input/ent-private-test/ENTRep_Track1_Private_Data/cls.csv\"\n",
        "img_dir = \"/kaggle/input/ent-private-test/ENTRep_Private_Dataset_Update/imgs\"\n",
        "output_path = \"/kaggle/working/predictions.json\"\n",
        "\n",
        "predictor = TestPredictor(model_dir)\n",
        "predictions = predictor.predict_and_save(\n",
        "    csv_path=csv_path,\n",
        "    img_dir=img_dir,\n",
        "    output_path=output_path,\n",
        "    use_tta=True\n",
        ")\n",
        "\n",
        "print(f\"Results saved to: {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
