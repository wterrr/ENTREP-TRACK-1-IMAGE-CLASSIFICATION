{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SywOJ8n2OA_T"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZFxCPt4N6Oi"
      },
      "outputs": [],
      "source": [
        "!gdown 1I56vd3aWsy_nkY6zdXk4faIM6NSS5mer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3_WZdqVOEro"
      },
      "outputs": [],
      "source": [
        "!unzip /kaggle/working/data_cifar10_style_public.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5A6ny3YOFqR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import timm\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZDPx2YVOIrR"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise:\n",
        "    \"\"\"Thêm noise\"\"\"\n",
        "    def __init__(self, mean=0., std=0.02):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwXbAj07OLYh"
      },
      "outputs": [],
      "source": [
        "class SimulateEndoscopeLighting:\n",
        "    def __init__(self, severity=0.3):\n",
        "        self.severity = severity\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_array = np.array(img).astype(np.float32)\n",
        "        h, w = img_array.shape[:2]\n",
        "\n",
        "        # Vignetting effect\n",
        "        center_x, center_y = w // 2, h // 2\n",
        "        Y, X = np.ogrid[:h, :w]\n",
        "        dist = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n",
        "        max_dist = np.sqrt(center_x**2 + center_y**2)\n",
        "        mask = 1 - (dist / max_dist) * self.severity\n",
        "\n",
        "        for c in range(3):\n",
        "            img_array[:, :, c] *= mask\n",
        "\n",
        "        return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnikKjhSOOdx"
      },
      "outputs": [],
      "source": [
        "class ResizeOrPad:\n",
        "    \"\"\"Resize ảnh hoặc pad để handle ảnh nhỏ\"\"\"\n",
        "    def __init__(self, min_size):\n",
        "        self.min_size = min_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if w < self.min_size or h < self.min_size:\n",
        "            scale = self.min_size / min(w, h)\n",
        "            new_w = int(w * scale)\n",
        "            new_h = int(h * scale)\n",
        "            return T.functional.resize(img, (new_h, new_w))\n",
        "        return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHmREqiJOTUy"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.5, label_smoothing=0.05):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        n_classes = inputs.size(-1)\n",
        "        device = inputs.device\n",
        "\n",
        "        targets_one_hot = F.one_hot(targets, n_classes).float()\n",
        "        targets_smooth = targets_one_hot * (1 - self.label_smoothing) + self.label_smoothing / n_classes\n",
        "\n",
        "        p = F.softmax(inputs, dim=-1)\n",
        "        ce_loss = -targets_smooth * torch.log(p + 1e-8)\n",
        "        p_t = p.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
        "        focal_weight = (1 - p_t).pow(self.gamma)\n",
        "\n",
        "        focal_loss = focal_weight.unsqueeze(1) * ce_loss\n",
        "        return focal_loss.sum(dim=1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BokjkB7OXA5"
      },
      "outputs": [],
      "source": [
        "class EarDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm_pe5nROY7p"
      },
      "outputs": [],
      "source": [
        "class EndoscopyClassifier:\n",
        "    def __init__(self, data_path, project_name=\"endoscopy_95\", test_size=0.2):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.project_name = project_name\n",
        "        self.test_size = test_size\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.results_dir = Path(f\"results_{project_name}\")\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.setup_logging()\n",
        "\n",
        "        self.class_names = [\n",
        "            \"nose-right\",   # 0\n",
        "            \"nose-left\",    # 1\n",
        "            \"ear-right\",    # 2\n",
        "            \"ear-left\",     # 3\n",
        "            \"vc-open\",      # 4\n",
        "            \"vc-closed\",    # 5\n",
        "            \"throat\"        # 6\n",
        "        ]\n",
        "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
        "        self.idx_to_class = {idx: name for name, idx in self.class_to_idx.items()}\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "        # Phân loại orientation\n",
        "        self.left_classes = [1, 3]  # nose-left, ear-left\n",
        "        self.right_classes = [0, 2]  # nose-right, ear-right\n",
        "        self.other_classes = [4, 5, 6]  # vc-open, vc-closed, throat\n",
        "\n",
        "        self.log(\"Device: {}\".format(self.device))\n",
        "\n",
        "    def setup_logging(self):\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.log_file = self.results_dir / f\"log_{timestamp}.txt\"\n",
        "\n",
        "        def log_print(*args, **kwargs):\n",
        "            message = \" \".join(str(arg) for arg in args)\n",
        "            print(message, **kwargs)\n",
        "            with open(self.log_file, 'a', encoding='utf-8') as f:\n",
        "                f.write(f\"[{datetime.now().strftime('%H:%M:%S')}] {message}\\n\")\n",
        "\n",
        "        self.log = log_print\n",
        "\n",
        "    def collect_dataset(self):\n",
        "        self.log(\"Collecting dataset...\")\n",
        "\n",
        "        all_files = []\n",
        "        all_labels = []\n",
        "\n",
        "        for idx, class_name in enumerate(self.class_names):\n",
        "            class_dir = self.data_path / class_name\n",
        "            if class_dir.exists():\n",
        "                images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
        "                all_files.extend([str(img) for img in images])\n",
        "                all_labels.extend([idx] * len(images))\n",
        "                self.log(f\"   {class_name}: {len(images)} images\")\n",
        "\n",
        "        train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "            all_files, all_labels,\n",
        "            test_size=self.test_size,\n",
        "            stratify=all_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.log(f\"Total: {len(all_files)} images\")\n",
        "        self.log(f\"Train: {len(train_files)}, Test: {len(test_files)}\")\n",
        "\n",
        "        return train_files, train_labels, test_files, test_labels\n",
        "\n",
        "    def setup_safe_augmentation(self, img_size=224, phase=\"moderate\"):\n",
        "\n",
        "        if phase == \"gentle\":\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 10),\n",
        "                T.Resize((img_size + 10, img_size + 10)),\n",
        "                T.CenterCrop(img_size),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "        elif phase == \"moderate\":\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 30),\n",
        "                T.Resize((img_size + 20, img_size + 20)),\n",
        "                T.RandomCrop(img_size),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.05)\n",
        "                ], p=0.8),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    SimulateEndoscopeLighting(severity=0.3)\n",
        "                ], p=0.3),\n",
        "\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=2.0),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=0.5),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                AddGaussianNoise(std=0.01),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                T.RandomErasing(p=0.15, scale=(0.02, 0.12))\n",
        "            ])\n",
        "\n",
        "        else:\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 40),\n",
        "                T.RandomChoice([\n",
        "                    T.Compose([T.Resize((img_size + 40, img_size + 40)), T.CenterCrop(img_size)]),\n",
        "                    T.Compose([T.Resize((img_size + 20, img_size + 20)), T.CenterCrop(img_size)]),\n",
        "                    T.Compose([T.Resize((img_size, img_size))]),\n",
        "                    T.Compose([T.Resize((img_size + 32, img_size + 32)), T.RandomCrop(img_size)]),\n",
        "                ]),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.08)\n",
        "                ], p=0.9),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    SimulateEndoscopeLighting(severity=random.uniform(0.2, 0.4))\n",
        "                ], p=0.5),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.RandomAutocontrast(),\n",
        "                    T.RandomEqualize(),\n",
        "                ], p=0.3),\n",
        "\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
        "                    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=0.3),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=3.0),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                AddGaussianNoise(std=0.02),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                T.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.5, 2.0))\n",
        "            ])\n",
        "\n",
        "        val_transform = T.Compose([\n",
        "            ResizeOrPad(img_size),\n",
        "            T.Resize((img_size, img_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        return train_transform, val_transform\n",
        "\n",
        "    def safe_mixup(self, x, y, alpha=0.2):\n",
        "        if np.random.rand() > 0.5:\n",
        "            return x, y, y, 1.0\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        indices = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            current_class = y[i].item()\n",
        "\n",
        "            if current_class in self.left_classes:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.left_classes and j != i]\n",
        "            elif current_class in self.right_classes:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.right_classes and j != i]\n",
        "            else:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.other_classes and j != i]\n",
        "\n",
        "            if valid_indices:\n",
        "                idx = np.random.choice(valid_indices)\n",
        "            else:\n",
        "                idx = i\n",
        "            indices.append(idx)\n",
        "\n",
        "        indices = torch.tensor(indices).to(x.device)\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        lam = max(lam, 1 - lam)\n",
        "\n",
        "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
        "        return mixed_x, y, y[indices], lam\n",
        "\n",
        "    def create_models(self):\n",
        "        models_config = [\n",
        "            {\"name\": \"convnext_base.fb_in22k_ft_in1k\", \"img_size\": 224},\n",
        "        ]\n",
        "\n",
        "        models = []\n",
        "        for config in models_config:\n",
        "            try:\n",
        "                model = timm.create_model(\n",
        "                    config['name'],\n",
        "                    pretrained=True,\n",
        "                    num_classes=self.num_classes,\n",
        "                    drop_rate=0.4,\n",
        "                    drop_path_rate=0.3\n",
        "                )\n",
        "                models.append({'model': model, 'config': config})\n",
        "                self.log(f\"Created: {config['name']}\")\n",
        "            except:\n",
        "                self.log(f\"Failed: {config['name']}\")\n",
        "\n",
        "        return models\n",
        "\n",
        "    def train_single_model(self, model, train_files, train_labels, val_files, val_labels,\n",
        "                          model_name, fold=None):\n",
        "\n",
        "        model = model.to(self.device)\n",
        "        img_size = 224\n",
        "        best_acc = 0.0\n",
        "\n",
        "        # Phase 1: Freeze backbone\n",
        "        self.log(f\"\\nPhase 1: Training head only for {model_name}\" + (f\" (Fold {fold})\" if fold else \"\"))\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'head' in name or 'classifier' in name or 'fc' in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Phase 1 training\n",
        "        train_transform, val_transform = self.setup_safe_augmentation(img_size, \"gentle\")\n",
        "        train_dataset = EarDataset(train_files, train_labels, train_transform)\n",
        "        val_dataset = EarDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "        phase1_acc = self.train_phase(\n",
        "            model, train_dataset, val_dataset,\n",
        "            epochs=15, lr=5e-4, phase_name=\"head_only\"\n",
        "        )\n",
        "\n",
        "        if phase1_acc > best_acc:\n",
        "            best_acc = phase1_acc\n",
        "\n",
        "        # Phase 2: Unfreeze last layers\n",
        "        self.log(f\"\\nPhase 2: Fine-tuning last layers for {model_name}\")\n",
        "\n",
        "        # Unfreeze last 40% layers\n",
        "        all_params = list(model.named_parameters())\n",
        "        n_unfreeze = len(all_params) // 2\n",
        "        for name, param in all_params[-n_unfreeze:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "        train_transform, val_transform = self.setup_safe_augmentation(img_size, \"moderate\")\n",
        "        train_dataset = EarDataset(train_files, train_labels, train_transform)\n",
        "        val_dataset = EarDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "        phase2_acc = self.train_phase(\n",
        "            model, train_dataset, val_dataset,\n",
        "            epochs=40, lr=3e-4, phase_name=\"partial_finetune\"\n",
        "        )\n",
        "\n",
        "        if phase2_acc > best_acc:\n",
        "            best_acc = phase2_acc\n",
        "\n",
        "        # Phase 3: Full fine-tuning if needed\n",
        "        if best_acc < 0.92:\n",
        "            self.log(f\"\\nPhase 3: Full fine-tuning for {model_name}\")\n",
        "\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "            train_transform, val_transform = self.setup_safe_augmentation(img_size, \"strong\")\n",
        "            train_dataset = EarDataset(train_files, train_labels, train_transform)\n",
        "            val_dataset = EarDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "            phase3_acc = self.train_phase(\n",
        "                model, train_dataset, val_dataset,\n",
        "                epochs=30, lr=1e-4, phase_name=\"full_finetune\"\n",
        "            )\n",
        "\n",
        "            if phase3_acc > best_acc:\n",
        "                best_acc = phase3_acc\n",
        "\n",
        "        return model, best_acc\n",
        "\n",
        "    def train_phase(self, model, train_dataset, val_dataset, epochs, lr, phase_name):\n",
        "\n",
        "        # Weighted sampler cho imbalanced data\n",
        "        class_counts = np.bincount(train_dataset.labels)\n",
        "        weights = 1.0 / class_counts[train_dataset.labels]\n",
        "        sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset, batch_size=16, sampler=sampler,\n",
        "            num_workers=4, pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset, batch_size=16, shuffle=False,\n",
        "            num_workers=4, pin_memory=True\n",
        "        )\n",
        "\n",
        "        backbone_params = []\n",
        "        head_params = []\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                if 'head' in name or 'classifier' in name or 'fc' in name:\n",
        "                    head_params.append(param)\n",
        "                else:\n",
        "                    backbone_params.append(param)\n",
        "\n",
        "        optimizer = optim.AdamW([\n",
        "            {'params': backbone_params, 'lr': lr * 0.1},\n",
        "            {'params': head_params, 'lr': lr}\n",
        "        ], weight_decay=0.01)\n",
        "\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=10, T_mult=2, eta_min=lr*0.001\n",
        "        )\n",
        "\n",
        "        criterion = FocalLoss(gamma=1.5, label_smoothing=0.05)\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        patience = 15\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f\"{phase_name} E{epoch+1}/{epochs}\")\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                images, targets_a, targets_b, lam = self.safe_mixup(images, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "\n",
        "                if lam == 1.0:\n",
        "                    loss = criterion(outputs, targets_a)\n",
        "                else:\n",
        "                    loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_acc = val_correct / val_total\n",
        "            train_acc = correct / total\n",
        "\n",
        "            self.log(f\"   E{epoch+1}: Train {train_acc:.4f}, Val {val_acc:.4f}\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), self.results_dir / f\"best_{phase_name}_model.pt\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                self.log(f\"   Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        model.load_state_dict(torch.load(self.results_dir / f\"best_{phase_name}_model.pt\"))\n",
        "\n",
        "        return best_val_acc\n",
        "\n",
        "    def train_kfold_ensemble(self, all_files, all_labels, n_splits=5):\n",
        "        self.log(\"\\nTraining K-Fold Ensemble...\")\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "        fold_models = []\n",
        "\n",
        "        base_models = self.create_models()\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(all_files, all_labels)):\n",
        "            self.log(f\"\\nFold {fold+1}/{n_splits}\")\n",
        "\n",
        "            fold_train_files = [all_files[i] for i in train_idx]\n",
        "            fold_train_labels = [all_labels[i] for i in train_idx]\n",
        "            fold_val_files = [all_files[i] for i in val_idx]\n",
        "            fold_val_labels = [all_labels[i] for i in val_idx]\n",
        "\n",
        "            for model_info in base_models:\n",
        "                model_name = model_info['config']['name']\n",
        "                self.log(f\"\\nTraining {model_name} on Fold {fold+1}\")\n",
        "\n",
        "                model = timm.create_model(\n",
        "                    model_name,\n",
        "                    pretrained=True,\n",
        "                    num_classes=self.num_classes,\n",
        "                    drop_rate=0.4,\n",
        "                    drop_path_rate=0.3\n",
        "                )\n",
        "\n",
        "                trained_model, accuracy = self.train_single_model(\n",
        "                    model,\n",
        "                    fold_train_files, fold_train_labels,\n",
        "                    fold_val_files, fold_val_labels,\n",
        "                    model_name, fold+1\n",
        "                )\n",
        "\n",
        "                fold_models.append({\n",
        "                    'model': trained_model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'name': f\"{model_name}_fold{fold+1}\"\n",
        "                })\n",
        "\n",
        "        return fold_models\n",
        "\n",
        "    def evaluate_with_tta(self, model, test_files, test_labels, img_size=224, n_aug=5):\n",
        "\n",
        "        tta_transforms = [\n",
        "            T.Compose([\n",
        "                ResizeOrPad(img_size),\n",
        "                T.Resize((img_size, img_size)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ]\n",
        "\n",
        "        for i in range(n_aug - 1):\n",
        "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
        "            target_size = max(img_size, img_size + resize_delta)\n",
        "\n",
        "            transform = T.Compose([\n",
        "                ResizeOrPad(target_size + 20),\n",
        "                T.Resize((target_size + 10, target_size + 10)),\n",
        "                T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(\n",
        "                        brightness=random.uniform(0.1, 0.2),\n",
        "                        contrast=random.uniform(0.1, 0.2),\n",
        "                        saturation=random.uniform(0.05, 0.15),\n",
        "                        hue=random.uniform(0.02, 0.05)\n",
        "                    )\n",
        "                ], p=0.8),\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            tta_transforms.append(transform)\n",
        "\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for img_path, label in tqdm(zip(test_files, test_labels), total=len(test_files), desc=\"TTA Evaluation\"):\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "                aug_probs = []\n",
        "                for transform in tta_transforms:\n",
        "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                    output = model(img_tensor)\n",
        "                    probs = F.softmax(output, dim=1)\n",
        "                    aug_probs.append(probs)\n",
        "\n",
        "                weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
        "                weights = weights / weights.sum()\n",
        "\n",
        "                final_probs = torch.zeros_like(aug_probs[0])\n",
        "                for i, probs in enumerate(aug_probs):\n",
        "                    final_probs += probs * weights[i]\n",
        "\n",
        "                conf, pred = torch.max(final_probs, 1)\n",
        "\n",
        "                all_predictions.append(pred.item())\n",
        "                all_labels.append(label)\n",
        "                all_probs.append(final_probs.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        return accuracy, all_predictions, all_labels, all_probs\n",
        "\n",
        "    def ensemble_predict(self, models, test_files, test_labels, use_tta=True):\n",
        "        self.log(\"\\nEnsemble Prediction...\")\n",
        "\n",
        "        all_model_probs = []\n",
        "        model_weights = []\n",
        "\n",
        "        for model_info in models:\n",
        "            model = model_info['model']\n",
        "            accuracy = model_info['accuracy']\n",
        "            name = model_info.get('name', 'model')\n",
        "\n",
        "            self.log(f\"Getting predictions from {name} (acc: {accuracy:.4f})\")\n",
        "\n",
        "            if use_tta:\n",
        "                _, _, _, probs = self.evaluate_with_tta(\n",
        "                    model, test_files, test_labels, n_aug=3\n",
        "                )\n",
        "            else:\n",
        "                model.eval()\n",
        "                probs = []\n",
        "\n",
        "                transform = T.Compose([\n",
        "                    ResizeOrPad(224),\n",
        "                    T.Resize((224, 224)),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for img_path in test_files:\n",
        "                        image = Image.open(img_path).convert('RGB')\n",
        "                        img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                        output = model(img_tensor)\n",
        "                        prob = F.softmax(output, dim=1).cpu().numpy()\n",
        "                        probs.append(prob)\n",
        "\n",
        "            all_model_probs.append(np.array(probs).squeeze())\n",
        "            model_weights.append(accuracy ** 2)\n",
        "\n",
        "        model_weights = np.array(model_weights)\n",
        "        model_weights = model_weights / model_weights.sum()\n",
        "\n",
        "        final_probs = np.zeros_like(all_model_probs[0])\n",
        "        for i, probs in enumerate(all_model_probs):\n",
        "            final_probs += probs * model_weights[i]\n",
        "\n",
        "        predictions = np.argmax(final_probs, axis=1)\n",
        "        accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "        return accuracy, predictions, final_probs\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        try:\n",
        "            train_files, train_labels, test_files, test_labels = self.collect_dataset()\n",
        "            all_files = train_files + test_files\n",
        "            all_labels = train_labels + test_labels\n",
        "\n",
        "            fold_models = self.train_kfold_ensemble(all_files, all_labels, n_splits=5)\n",
        "\n",
        "            self.log(\"\\nTraining additional models on full training set...\")\n",
        "            full_models = self.create_models()\n",
        "\n",
        "            for model_info in full_models:\n",
        "                model_name = model_info['config']['name']\n",
        "                self.log(f\"\\nTraining {model_name} on full train set\")\n",
        "\n",
        "                trained_model, accuracy = self.train_single_model(\n",
        "                    model_info['model'],\n",
        "                    train_files, train_labels,\n",
        "                    test_files, test_labels,\n",
        "                    model_name\n",
        "                )\n",
        "\n",
        "                fold_models.append({\n",
        "                    'model': trained_model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'name': f\"{model_name}_full\"\n",
        "                })\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"INDIVIDUAL MODEL RESULTS WITH TTA:\")\n",
        "\n",
        "            best_single_acc = 0\n",
        "            for model_info in fold_models:\n",
        "                tta_acc, _, _, _ = self.evaluate_with_tta(\n",
        "                    model_info['model'], test_files, test_labels, n_aug=5\n",
        "                )\n",
        "                self.log(f\"{model_info['name']}: {tta_acc:.4f} ({tta_acc*100:.2f}%)\")\n",
        "\n",
        "                if tta_acc > best_single_acc:\n",
        "                    best_single_acc = tta_acc\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"ENSEMBLE RESULTS:\")\n",
        "\n",
        "            fold_models.sort(key=lambda x: x['accuracy'], reverse=True)\n",
        "            top_models = fold_models[:7]\n",
        "\n",
        "            ensemble_acc, _, _ = self.ensemble_predict(\n",
        "                top_models, test_files, test_labels, use_tta=False\n",
        "            )\n",
        "            self.log(f\"Ensemble (no TTA): {ensemble_acc:.4f} ({ensemble_acc*100:.2f}%)\")\n",
        "\n",
        "            ensemble_tta_acc, predictions, probs = self.ensemble_predict(\n",
        "                top_models, test_files, test_labels, use_tta=True\n",
        "            )\n",
        "            self.log(f\"Ensemble with TTA: {ensemble_tta_acc:.4f} ({ensemble_tta_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"DETAILED CLASSIFICATION REPORT:\")\n",
        "\n",
        "            report = classification_report(\n",
        "                test_labels, predictions,\n",
        "                target_names=self.class_names,\n",
        "                digits=4\n",
        "            )\n",
        "            self.log(report)\n",
        "\n",
        "            cm = confusion_matrix(test_labels, predictions)\n",
        "            self.log(\"\\nConfusion Matrix:\")\n",
        "            self.log(str(cm))\n",
        "\n",
        "            self.log(\"\\nPer-class Accuracy:\")\n",
        "            for i, class_name in enumerate(self.class_names):\n",
        "                class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
        "                self.log(f\"   {class_name}: {class_acc:.4f} ({class_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*80)\n",
        "            self.log(\"FINAL RESULTS:\")\n",
        "            self.log(f\"Best Single Model with TTA: {best_single_acc:.4f} ({best_single_acc*100:.2f}%)\")\n",
        "            self.log(f\"Ensemble with TTA: {ensemble_tta_acc:.4f} ({ensemble_tta_acc*100:.2f}%)\")\n",
        "\n",
        "            final_accuracy = max(best_single_acc, ensemble_tta_acc)\n",
        "\n",
        "            self.log(\"\\nSaving models...\")\n",
        "            ensemble_info = {\n",
        "                'models': [m['name'] for m in top_models],\n",
        "                'weights': [m['accuracy'] for m in top_models],\n",
        "                'final_accuracy': ensemble_tta_acc,\n",
        "                'class_names': self.class_names\n",
        "            }\n",
        "\n",
        "            import pickle\n",
        "            with open(self.results_dir / 'ensemble_info.pkl', 'wb') as f:\n",
        "                pickle.dump(ensemble_info, f)\n",
        "\n",
        "            for i, model_info in enumerate(top_models):\n",
        "                torch.save(\n",
        "                    model_info['model'].state_dict(),\n",
        "                    self.results_dir / f\"ensemble_model_{i}.pt\"\n",
        "                )\n",
        "\n",
        "            self.log(f\"\\nResults saved to: {self.results_dir}\")\n",
        "\n",
        "            return {\n",
        "                'final_accuracy': final_accuracy,\n",
        "                'ensemble_accuracy': ensemble_tta_acc,\n",
        "                'best_single_accuracy': best_single_acc,\n",
        "                'num_models': len(top_models)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log(f\"Error: {e}\")\n",
        "            import traceback\n",
        "            self.log(traceback.format_exc())\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxCMtkDcPYOB"
      },
      "outputs": [],
      "source": [
        "data_path = \"/kaggle/working/data_cifar10_style_public\"\n",
        "classifier = EndoscopyClassifier(data_path, test_size=0.2)\n",
        "\n",
        "results = classifier.run_pipeline()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
