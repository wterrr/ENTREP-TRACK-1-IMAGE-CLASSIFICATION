{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Pipeline"
      ],
      "metadata": {
        "id": "qwX_LskXSMKi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ezx072GSHyH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestPredictor:\n",
        "    def __init__(self, model_dir, device='cuda'):\n",
        "        self.model_dir = Path(model_dir)\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.class_names = [\n",
        "            \"nose-right\", \"nose-left\", \"ear-right\",\n",
        "            \"ear-left\", \"vc-open\", \"vc-closed\", \"throat\"\n",
        "        ]\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "    def load_ensemble_models(self):\n",
        "        print(\"Loading ensemble models...\")\n",
        "\n",
        "        with open(self.model_dir / 'ensemble_info.pkl', 'rb') as f:\n",
        "            ensemble_info = pickle.load(f)\n",
        "\n",
        "        models = []\n",
        "        model_names = ensemble_info['models']\n",
        "        weights = ensemble_info['weights']\n",
        "\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            print(f\"Loading model {i+1}/{len(model_names)}: {model_name}\")\n",
        "\n",
        "            base_name = \"convnext_base.fb_in22k_ft_in1k\"\n",
        "\n",
        "            model = timm.create_model(base_name, pretrained=False, num_classes=self.num_classes)\n",
        "            state_dict = torch.load(self.model_dir / f\"ensemble_model_{i}.pt\", map_location=self.device)\n",
        "            model.load_state_dict(state_dict)\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "\n",
        "            models.append({'model': model, 'weight': weights[i], 'name': model_name})\n",
        "\n",
        "        print(f\"Loaded {len(models)} models successfully.\")\n",
        "        return models\n",
        "\n",
        "    def load_test_data(self, csv_path, img_dir):\n",
        "        test_files = []\n",
        "        with open(csv_path, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                if row:\n",
        "                    img_name = row[0].strip()\n",
        "                    img_path = Path(img_dir) / img_name\n",
        "                    if img_path.exists():\n",
        "                        test_files.append(str(img_path))\n",
        "                    else:\n",
        "                        print(f\"Warning: Image not found: {img_path}\")\n",
        "\n",
        "        print(f\"Loaded {len(test_files)} test images.\")\n",
        "        return test_files\n",
        "\n",
        "    def get_tta_transforms(self, img_size=224, n_aug=5):\n",
        "        class ResizeOrPad:\n",
        "            def __init__(self, min_size):\n",
        "                self.min_size = min_size\n",
        "\n",
        "            def __call__(self, img):\n",
        "                w, h = img.size\n",
        "                if w < self.min_size or h < self.min_size:\n",
        "                    scale = self.min_size / min(w, h)\n",
        "                    new_w = int(w * scale)\n",
        "                    new_h = int(h * scale)\n",
        "                    return T.functional.resize(img, (new_h, new_w))\n",
        "                return img\n",
        "\n",
        "        transforms = [\n",
        "            T.Compose([\n",
        "                ResizeOrPad(img_size),\n",
        "                T.Resize((img_size, img_size)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ]\n",
        "\n",
        "        import random\n",
        "        for i in range(n_aug - 1):\n",
        "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
        "            target_size = max(img_size, img_size + resize_delta)\n",
        "\n",
        "            transforms.append(\n",
        "                T.Compose([\n",
        "                    ResizeOrPad(target_size + 20),\n",
        "                    T.Resize((target_size + 10, target_size + 10)),\n",
        "                    T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
        "                    T.RandomApply([\n",
        "                        T.ColorJitter(\n",
        "                            brightness=random.uniform(0.1, 0.2),\n",
        "                            contrast=random.uniform(0.1, 0.2),\n",
        "                            saturation=random.uniform(0.05, 0.15),\n",
        "                            hue=random.uniform(0.02, 0.05)\n",
        "                        )\n",
        "                    ], p=0.8),\n",
        "                    T.RandomChoice([\n",
        "                        T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
        "                        nn.Identity()\n",
        "                    ]),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "            )\n",
        "        return transforms\n",
        "\n",
        "    def predict_single_image_tta(self, model, img_path, n_aug=5):\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        tta_transforms = self.get_tta_transforms(n_aug=n_aug)\n",
        "\n",
        "        aug_probs = []\n",
        "        with torch.no_grad():\n",
        "            for transform in tta_transforms:\n",
        "                img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                output = model(img_tensor)\n",
        "                probs = F.softmax(output, dim=1)\n",
        "                aug_probs.append(probs)\n",
        "\n",
        "        weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
        "        weights = weights / weights.sum()\n",
        "\n",
        "        final_probs = torch.zeros_like(aug_probs[0])\n",
        "        for i, probs in enumerate(aug_probs):\n",
        "            final_probs += probs * weights[i]\n",
        "\n",
        "        return final_probs.cpu().numpy().squeeze()\n",
        "\n",
        "    def ensemble_predict_batch(self, models, test_files, use_tta=True, batch_size=32):\n",
        "        predictions = {}\n",
        "        for img_path in tqdm(test_files, desc=\"Predicting\"):\n",
        "            img_name = Path(img_path).name\n",
        "            all_model_probs = []\n",
        "            model_weights = []\n",
        "\n",
        "            for model_info in models:\n",
        "                model = model_info['model']\n",
        "                weight = model_info['weight']\n",
        "\n",
        "                if use_tta:\n",
        "                    probs = self.predict_single_image_tta(model, img_path, n_aug=3)\n",
        "                else:\n",
        "                    transform = T.Compose([\n",
        "                        T.Resize((224, 224)),\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "                    ])\n",
        "                    image = Image.open(img_path).convert('RGB')\n",
        "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        output = model(img_tensor)\n",
        "                        probs = F.softmax(output, dim=1).cpu().numpy().squeeze()\n",
        "\n",
        "                all_model_probs.append(probs)\n",
        "                model_weights.append(weight ** 2)\n",
        "\n",
        "            model_weights = np.array(model_weights)\n",
        "            model_weights /= model_weights.sum()\n",
        "\n",
        "            final_probs = np.zeros_like(all_model_probs[0])\n",
        "            for i, probs in enumerate(all_model_probs):\n",
        "                final_probs += probs * model_weights[i]\n",
        "\n",
        "            pred_class = np.argmax(final_probs)\n",
        "            predictions[img_name] = int(pred_class)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def predict_and_save(self, csv_path, img_dir, output_path, use_tta=True):\n",
        "        models = self.load_ensemble_models()\n",
        "        test_files = self.load_test_data(csv_path, img_dir)\n",
        "\n",
        "        print(\"\\nStarting prediction...\")\n",
        "        predictions = self.ensemble_predict_batch(models, test_files, use_tta=use_tta)\n",
        "\n",
        "        print(f\"\\nSaving results to {output_path}\")\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(predictions, f, indent=2)\n",
        "\n",
        "        print(f\"Saved {len(predictions)} predictions\")\n",
        "\n",
        "        print(\"\\nSample predictions:\")\n",
        "        for i, (img_name, pred) in enumerate(list(predictions.items())[:5]):\n",
        "            print(f\"  {img_name}: {pred} ({self.class_names[pred]})\")\n",
        "\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "KBFmoqwdSR0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/kaggle/input/convnextbase-ensemble-metalearner\"\n",
        "csv_path = \"//kaggle/input/ent-private-test/ENTRep_Track1_Private_Data/cls.csv\"\n",
        "img_dir = \"/kaggle/input/ent-private-test/ENTRep_Private_Dataset_Update/imgs\"\n",
        "output_path = \"/kaggle/working/predictions.json\"\n",
        "\n",
        "predictor = TestPredictor(model_dir)\n",
        "predictions = predictor.predict_and_save(\n",
        "    csv_path=csv_path,\n",
        "    img_dir=img_dir,\n",
        "    output_path=output_path,\n",
        "    use_tta=True\n",
        ")\n",
        "\n",
        "print(f\"Results saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "46tppNu1SdmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Pipeline cải tiến"
      ],
      "metadata": {
        "id": "Cw_xdB4ZSi4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import pickle\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    from peft import LoraConfig, get_peft_model, PeftModel\n",
        "    PEFT_AVAILABLE = True\n",
        "    print(\"PEFT library is available.\")\n",
        "except ImportError:\n",
        "    PEFT_AVAILABLE = False\n",
        "    print(\"Warning: PEFT library not found. Model loading might fail if PEFT was used during training.\")"
      ],
      "metadata": {
        "id": "Qc3RFanYSlQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeOrPad:\n",
        "    def __init__(self, min_size):\n",
        "        self.min_size = min_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if w < self.min_size or h < self.min_size:\n",
        "            scale = self.min_size / min(w, h)\n",
        "            new_w = int(w * scale)\n",
        "            new_h = int(h * scale)\n",
        "            return T.functional.resize(img, (new_h, new_w))\n",
        "        return img\n",
        "\n",
        "class AnatomicalGroupAuxiliaryModel(nn.Module):\n",
        "    def __init__(self, backbone_name, num_classes=7, num_groups=4, drop_rate=0.4, drop_path_rate=0.3,\n",
        "                 use_peft=True, lora_rank=16, lora_alpha=32, lora_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.use_peft = use_peft and PEFT_AVAILABLE\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone_name, pretrained=False, num_classes=0,\n",
        "            drop_rate=drop_rate, drop_path_rate=drop_path_rate\n",
        "        )\n",
        "        feature_dim = self.backbone.num_features\n",
        "\n",
        "        self.primary_head = nn.Sequential(nn.Dropout(drop_rate), nn.Linear(feature_dim, num_classes))\n",
        "        self.auxiliary_head = nn.Sequential(nn.Dropout(drop_rate), nn.Linear(feature_dim, num_groups))\n",
        "\n",
        "        if self.use_peft:\n",
        "            self._apply_peft(lora_rank, lora_alpha, lora_dropout)\n",
        "\n",
        "    def _apply_peft(self, rank, alpha, dropout):\n",
        "        if not PEFT_AVAILABLE: return\n",
        "        target_modules = [name for name, module in self.backbone.named_modules() if isinstance(module, nn.Linear)]\n",
        "        peft_config = LoraConfig(\n",
        "            r=rank, lora_alpha=alpha, lora_dropout=dropout,\n",
        "            target_modules=target_modules, bias=\"none\"\n",
        "        )\n",
        "        self.backbone = get_peft_model(self.backbone, peft_config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        primary_logits = self.primary_head(features)\n",
        "        auxiliary_logits = self.auxiliary_head(features)\n",
        "        return primary_logits, auxiliary_logits"
      ],
      "metadata": {
        "id": "KoPxm0lVSnFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestPredictor:\n",
        "    def __init__(self, model_dir, device='cuda'):\n",
        "        self.model_dir = Path(model_dir)\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.class_names = [\n",
        "            \"nose-right\", \"nose-left\", \"ear-right\",\n",
        "            \"ear-left\", \"vc-open\", \"vc-closed\", \"throat\"\n",
        "        ]\n",
        "        self.num_classes = len(self.class_names)\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "    def load_ensemble_models(self):\n",
        "        print(\"Loading PEFT-trained ensemble models...\")\n",
        "\n",
        "        try:\n",
        "            with open(self.model_dir / 'ensemble_info.pkl', 'rb') as f:\n",
        "                ensemble_info = pickle.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: 'ensemble_info.pkl' not found in {self.model_dir}\")\n",
        "            return []\n",
        "\n",
        "        models = []\n",
        "        model_names = ensemble_info.get('models', [])\n",
        "        weights = ensemble_info.get('weights', [])\n",
        "        peft_config = ensemble_info.get('peft_config', {'use_peft': True, 'rank': 16, 'alpha': 32})\n",
        "\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            print(f\"Loading model {i+1}/{len(model_names)}: {model_name}\")\n",
        "\n",
        "            base_name = model_name\n",
        "            if base_name.endswith('_full'):\n",
        "                base_name = base_name[:-5]\n",
        "            elif '_fold' in base_name:\n",
        "                base_name = base_name.rsplit('_', 1)[0]\n",
        "\n",
        "            backbone_name = base_name\n",
        "\n",
        "            model = AnatomicalGroupAuxiliaryModel(\n",
        "                backbone_name=backbone_name,\n",
        "                num_classes=self.num_classes,\n",
        "                num_groups=4,\n",
        "                use_peft=peft_config.get('use_peft', True),\n",
        "                lora_rank=peft_config.get('rank', 16),\n",
        "                lora_alpha=peft_config.get('alpha', 32)\n",
        "            )\n",
        "\n",
        "            state_dict_path = self.model_dir / f\"ensemble_model_{i}.pt\"\n",
        "            state_dict = torch.load(state_dict_path, map_location=self.device)\n",
        "            model.load_state_dict(state_dict)\n",
        "\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "\n",
        "            weight = weights[i] if i < len(weights) else 1.0\n",
        "            models.append({'model': model, 'weight': weight, 'name': model_name})\n",
        "\n",
        "        print(f\"Loaded {len(models)} models successfully.\")\n",
        "        return models\n",
        "\n",
        "    def load_test_data(self, csv_path, img_dir):\n",
        "        test_files = []\n",
        "        with open(csv_path, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                if row:\n",
        "                    img_name = row[0].strip()\n",
        "                    img_path = Path(img_dir) / img_name\n",
        "                    if img_path.exists():\n",
        "                        test_files.append(str(img_path))\n",
        "        print(f\"Loaded {len(test_files)} test images.\")\n",
        "        return test_files\n",
        "\n",
        "    def get_tta_transforms(self, img_size=224, n_aug=5):\n",
        "        transforms = [\n",
        "            T.Compose([\n",
        "                ResizeOrPad(img_size), T.Resize((img_size, img_size)), T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ]\n",
        "        for i in range(n_aug - 1):\n",
        "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
        "            target_size = max(img_size, img_size + resize_delta)\n",
        "            transforms.append(\n",
        "                T.Compose([\n",
        "                    ResizeOrPad(target_size + 20),\n",
        "                    T.Resize((target_size + 10, target_size + 10)),\n",
        "                    T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
        "                    T.RandomApply([T.ColorJitter(brightness=random.uniform(0.1, 0.2), contrast=random.uniform(0.1, 0.2), saturation=random.uniform(0.05, 0.15), hue=random.uniform(0.02, 0.05))], p=0.8),\n",
        "                    T.RandomChoice([T.GaussianBlur(3, sigma=(0.1, 0.5)), nn.Identity()]),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "            )\n",
        "        return transforms\n",
        "\n",
        "    def predict_single_image_tta(self, model, img_path, n_aug=5):\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        tta_transforms = self.get_tta_transforms(n_aug=n_aug)\n",
        "        aug_probs = []\n",
        "        with torch.no_grad():\n",
        "            for transform in tta_transforms:\n",
        "                img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                primary_output, _ = model(img_tensor)\n",
        "                probs = F.softmax(primary_output, dim=1)\n",
        "                aug_probs.append(probs)\n",
        "\n",
        "        weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
        "        weights = weights / weights.sum()\n",
        "        final_probs = torch.zeros_like(aug_probs[0])\n",
        "        for i, probs in enumerate(aug_probs):\n",
        "            final_probs += probs * weights[i]\n",
        "        return final_probs.cpu().numpy().squeeze()\n",
        "\n",
        "    def ensemble_predict_batch(self, models, test_files, use_tta=True):\n",
        "        predictions = {}\n",
        "        for img_path in tqdm(test_files, desc=\"Predicting\"):\n",
        "            img_name = Path(img_path).name\n",
        "            all_model_probs, model_weights = [], []\n",
        "            for model_info in models:\n",
        "                model, weight = model_info['model'], model_info['weight']\n",
        "                if use_tta:\n",
        "                    probs = self.predict_single_image_tta(model, img_path, n_aug=3)\n",
        "                else:\n",
        "                    transform = T.Compose([\n",
        "                        ResizeOrPad(224), T.Resize((224, 224)), T.ToTensor(),\n",
        "                        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                    ])\n",
        "                    image = Image.open(img_path).convert('RGB')\n",
        "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        primary_output, _ = model(img_tensor)\n",
        "                        probs = F.softmax(primary_output, dim=1).cpu().numpy().squeeze()\n",
        "                all_model_probs.append(probs)\n",
        "                model_weights.append(weight ** 2)\n",
        "\n",
        "            model_weights = np.array(model_weights)\n",
        "            model_weights /= model_weights.sum()\n",
        "            final_probs = np.sum([p * w for p, w in zip(all_model_probs, model_weights)], axis=0)\n",
        "            pred_class = np.argmax(final_probs)\n",
        "            predictions[img_name] = int(pred_class)\n",
        "        return predictions\n",
        "\n",
        "    def predict_and_save(self, csv_path, img_dir, output_path, use_tta=True):\n",
        "        models = self.load_ensemble_models()\n",
        "        if not models: return\n",
        "        test_files = self.load_test_data(csv_path, img_dir)\n",
        "        predictions = self.ensemble_predict_batch(models, test_files, use_tta=use_tta)\n",
        "        print(f\"\\nSaving results to {output_path}\")\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(predictions, f, indent=2)\n",
        "        print(f\"Saved {len(predictions)} predictions\")\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "TMUYd725SvwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/kaggle/input/bestmodel\"\n",
        "csv_path = \"/kaggle/input/ent-private-test/ENTRep_Track1_Private_Data/cls.csv\"\n",
        "img_dir = \"/kaggle/input/ent-private-test/ENTRep_Private_Dataset_Update/imgs\"\n",
        "output_path = \"best_predictions.json\"\n",
        "\n",
        "predictor = TestPredictor(model_dir)\n",
        "predictor.predict_and_save(\n",
        "    csv_path=csv_path,\n",
        "    img_dir=img_dir,\n",
        "    output_path=output_path,\n",
        "    use_tta=True\n",
        ")\n",
        "print(f\"\\nResults saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "PMXX-ivlS8MJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}