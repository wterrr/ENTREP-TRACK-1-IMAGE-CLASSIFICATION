{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "SywOJ8n2OA_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZFxCPt4N6Oi"
      },
      "outputs": [],
      "source": [
        "!gdown 1I56vd3aWsy_nkY6zdXk4faIM6NSS5mer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /kaggle/working/data_cifar10_style_public.zip"
      ],
      "metadata": {
        "id": "D3_WZdqVOEro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import timm\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random"
      ],
      "metadata": {
        "id": "g5A6ny3YOFqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddGaussianNoise:\n",
        "    \"\"\"Thêm noise\"\"\"\n",
        "    def __init__(self, mean=0., std=0.02):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean"
      ],
      "metadata": {
        "id": "VZDPx2YVOIrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimulateEndoscopeLighting:\n",
        "    def __init__(self, severity=0.3):\n",
        "        self.severity = severity\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_array = np.array(img).astype(np.float32)\n",
        "        h, w = img_array.shape[:2]\n",
        "\n",
        "        # Vignetting effect\n",
        "        center_x, center_y = w // 2, h // 2\n",
        "        Y, X = np.ogrid[:h, :w]\n",
        "        dist = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n",
        "        max_dist = np.sqrt(center_x**2 + center_y**2)\n",
        "        mask = 1 - (dist / max_dist) * self.severity\n",
        "\n",
        "        for c in range(3):\n",
        "            img_array[:, :, c] *= mask\n",
        "\n",
        "        return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))"
      ],
      "metadata": {
        "id": "bwXbAj07OLYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeOrPad:\n",
        "    \"\"\"Resize ảnh hoặc pad để handle ảnh nhỏ\"\"\"\n",
        "    def __init__(self, min_size):\n",
        "        self.min_size = min_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if w < self.min_size or h < self.min_size:\n",
        "            scale = self.min_size / min(w, h)\n",
        "            new_w = int(w * scale)\n",
        "            new_h = int(h * scale)\n",
        "            return T.functional.resize(img, (new_h, new_w))\n",
        "        return img"
      ],
      "metadata": {
        "id": "NnikKjhSOOdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.5, label_smoothing=0.05):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        n_classes = inputs.size(-1)\n",
        "        device = inputs.device\n",
        "\n",
        "        targets_one_hot = F.one_hot(targets, n_classes).float()\n",
        "        targets_smooth = targets_one_hot * (1 - self.label_smoothing) + self.label_smoothing / n_classes\n",
        "\n",
        "        p = F.softmax(inputs, dim=-1)\n",
        "        ce_loss = -targets_smooth * torch.log(p + 1e-8)\n",
        "        p_t = p.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
        "        focal_weight = (1 - p_t).pow(self.gamma)\n",
        "\n",
        "        focal_loss = focal_weight.unsqueeze(1) * ce_loss\n",
        "        return focal_loss.sum(dim=1).mean()"
      ],
      "metadata": {
        "id": "jHmREqiJOTUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "_BokjkB7OXA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EndoscopyClassifier:\n",
        "    def __init__(self, data_path, project_name=\"endoscopy_95\", test_size=0.2):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.project_name = project_name\n",
        "        self.test_size = test_size\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.results_dir = Path(f\"results_{project_name}\")\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.setup_logging()\n",
        "\n",
        "        self.class_names = [\n",
        "            \"nose-right\",   # 0\n",
        "            \"nose-left\",    # 1\n",
        "            \"ear-right\",    # 2\n",
        "            \"ear-left\",     # 3\n",
        "            \"vc-open\",      # 4\n",
        "            \"vc-closed\",    # 5\n",
        "            \"throat\"        # 6\n",
        "        ]\n",
        "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
        "        self.idx_to_class = {idx: name for name, idx in self.class_to_idx.items()}\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "        # Phân loại orientation\n",
        "        self.left_classes = [1, 3]  # nose-left, ear-left\n",
        "        self.right_classes = [0, 2]  # nose-right, ear-right\n",
        "        self.other_classes = [4, 5, 6]  # vc-open, vc-closed, throat\n",
        "\n",
        "        self.log(\"IMPROVED ENDOSCOPY CLASSIFIER - TARGET 95%\")\n",
        "        self.log(\"Device: {}\".format(self.device))\n",
        "\n",
        "    def setup_logging(self):\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.log_file = self.results_dir / f\"log_{timestamp}.txt\"\n",
        "\n",
        "        def log_print(*args, **kwargs):\n",
        "            message = \" \".join(str(arg) for arg in args)\n",
        "            print(message, **kwargs)\n",
        "            with open(self.log_file, 'a', encoding='utf-8') as f:\n",
        "                f.write(f\"[{datetime.now().strftime('%H:%M:%S')}] {message}\\n\")\n",
        "\n",
        "        self.log = log_print\n",
        "\n",
        "    def collect_dataset(self):\n",
        "        self.log(\"Collecting dataset...\")\n",
        "\n",
        "        all_files = []\n",
        "        all_labels = []\n",
        "\n",
        "        for idx, class_name in enumerate(self.class_names):\n",
        "            class_dir = self.data_path / class_name\n",
        "            if class_dir.exists():\n",
        "                images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
        "                all_files.extend([str(img) for img in images])\n",
        "                all_labels.extend([idx] * len(images))\n",
        "                self.log(f\"   {class_name}: {len(images)} images\")\n",
        "\n",
        "        train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "            all_files, all_labels,\n",
        "            test_size=self.test_size,\n",
        "            stratify=all_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.log(f\"Total: {len(all_files)} images\")\n",
        "        self.log(f\"Train: {len(train_files)}, Test: {len(test_files)}\")\n",
        "\n",
        "        return train_files, train_labels, test_files, test_labels\n",
        "\n",
        "    def setup_safe_augmentation(self, img_size=224, phase=\"moderate\"):\n",
        "\n",
        "        if phase == \"gentle\":\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 10),\n",
        "                T.Resize((img_size + 10, img_size + 10)),\n",
        "                T.CenterCrop(img_size),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "        elif phase == \"moderate\":\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 30),\n",
        "                T.Resize((img_size + 20, img_size + 20)),\n",
        "                T.RandomCrop(img_size),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.05)\n",
        "                ], p=0.8),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    SimulateEndoscopeLighting(severity=0.3)\n",
        "                ], p=0.3),\n",
        "\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=2.0),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=0.5),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                AddGaussianNoise(std=0.01),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                T.RandomErasing(p=0.15, scale=(0.02, 0.12))\n",
        "            ])\n",
        "\n",
        "        else:\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 40),\n",
        "                T.RandomChoice([\n",
        "                    T.Compose([T.Resize((img_size + 40, img_size + 40)), T.CenterCrop(img_size)]),\n",
        "                    T.Compose([T.Resize((img_size + 20, img_size + 20)), T.CenterCrop(img_size)]),\n",
        "                    T.Compose([T.Resize((img_size, img_size))]),\n",
        "                    T.Compose([T.Resize((img_size + 32, img_size + 32)), T.RandomCrop(img_size)]),\n",
        "                ]),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.08)\n",
        "                ], p=0.9),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    SimulateEndoscopeLighting(severity=random.uniform(0.2, 0.4))\n",
        "                ], p=0.5),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.RandomAutocontrast(),\n",
        "                    T.RandomEqualize(),\n",
        "                ], p=0.3),\n",
        "\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
        "                    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=0.3),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=3.0),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                AddGaussianNoise(std=0.02),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                T.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.5, 2.0))\n",
        "            ])\n",
        "\n",
        "        val_transform = T.Compose([\n",
        "            ResizeOrPad(img_size),\n",
        "            T.Resize((img_size, img_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        return train_transform, val_transform\n",
        "\n",
        "    def safe_mixup(self, x, y, alpha=0.2):\n",
        "        if np.random.rand() > 0.5:\n",
        "            return x, y, y, 1.0\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        indices = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            current_class = y[i].item()\n",
        "\n",
        "            if current_class in self.left_classes:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.left_classes and j != i]\n",
        "            elif current_class in self.right_classes:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.right_classes and j != i]\n",
        "            else:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.other_classes and j != i]\n",
        "\n",
        "            if valid_indices:\n",
        "                idx = np.random.choice(valid_indices)\n",
        "            else:\n",
        "                idx = i\n",
        "            indices.append(idx)\n",
        "\n",
        "        indices = torch.tensor(indices).to(x.device)\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        lam = max(lam, 1 - lam)\n",
        "\n",
        "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
        "        return mixed_x, y, y[indices], lam\n",
        "\n",
        "    def create_models(self):\n",
        "        models_config = [\n",
        "            {\"name\": \"convnext_base.fb_in22k_ft_in1k\", \"img_size\": 224},\n",
        "        ]\n",
        "\n",
        "        models = []\n",
        "        for config in models_config:\n",
        "            try:\n",
        "                model = timm.create_model(\n",
        "                    config['name'],\n",
        "                    pretrained=True,\n",
        "                    num_classes=self.num_classes,\n",
        "                    drop_rate=0.4,\n",
        "                    drop_path_rate=0.3\n",
        "                )\n",
        "                models.append({'model': model, 'config': config})\n",
        "                self.log(f\"Created: {config['name']}\")\n",
        "            except:\n",
        "                self.log(f\"Failed: {config['name']}\")\n",
        "\n",
        "        return models\n",
        "\n",
        "    def train_single_model(self, model, train_files, train_labels, val_files, val_labels,\n",
        "                          model_name, fold=None):\n",
        "\n",
        "        model = model.to(self.device)\n",
        "        img_size = 224\n",
        "        best_acc = 0.0\n",
        "\n",
        "        # Phase 1: Freeze backbone\n",
        "        self.log(f\"\\nPhase 1: Training head only for {model_name}\" + (f\" (Fold {fold})\" if fold else \"\"))\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'head' in name or 'classifier' in name or 'fc' in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Phase 1 training\n",
        "        train_transform, val_transform = self.setup_safe_augmentation(img_size, \"gentle\")\n",
        "        train_dataset = EarDataset(train_files, train_labels, train_transform)\n",
        "        val_dataset = EarDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "        phase1_acc = self.train_phase(\n",
        "            model, train_dataset, val_dataset,\n",
        "            epochs=15, lr=5e-4, phase_name=\"head_only\"\n",
        "        )\n",
        "\n",
        "        if phase1_acc > best_acc:\n",
        "            best_acc = phase1_acc\n",
        "\n",
        "        # Phase 2: Unfreeze last layers\n",
        "        self.log(f\"\\nPhase 2: Fine-tuning last layers for {model_name}\")\n",
        "\n",
        "        # Unfreeze last 40% layers\n",
        "        all_params = list(model.named_parameters())\n",
        "        n_unfreeze = len(all_params) // 2\n",
        "        for name, param in all_params[-n_unfreeze:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "        train_transform, val_transform = self.setup_safe_augmentation(img_size, \"moderate\")\n",
        "        train_dataset = EarDataset(train_files, train_labels, train_transform)\n",
        "        val_dataset = EarDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "        phase2_acc = self.train_phase(\n",
        "            model, train_dataset, val_dataset,\n",
        "            epochs=40, lr=3e-4, phase_name=\"partial_finetune\"\n",
        "        )\n",
        "\n",
        "        if phase2_acc > best_acc:\n",
        "            best_acc = phase2_acc\n",
        "\n",
        "        # Phase 3: Full fine-tuning if needed\n",
        "        if best_acc < 0.92:\n",
        "            self.log(f\"\\nPhase 3: Full fine-tuning for {model_name}\")\n",
        "\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "            train_transform, val_transform = self.setup_safe_augmentation(img_size, \"strong\")\n",
        "            train_dataset = EarDataset(train_files, train_labels, train_transform)\n",
        "            val_dataset = EarDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "            phase3_acc = self.train_phase(\n",
        "                model, train_dataset, val_dataset,\n",
        "                epochs=30, lr=1e-4, phase_name=\"full_finetune\"\n",
        "            )\n",
        "\n",
        "            if phase3_acc > best_acc:\n",
        "                best_acc = phase3_acc\n",
        "\n",
        "        return model, best_acc\n",
        "\n",
        "    def train_phase(self, model, train_dataset, val_dataset, epochs, lr, phase_name):\n",
        "\n",
        "        # Weighted sampler cho imbalanced data\n",
        "        class_counts = np.bincount(train_dataset.labels)\n",
        "        weights = 1.0 / class_counts[train_dataset.labels]\n",
        "        sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset, batch_size=16, sampler=sampler,\n",
        "            num_workers=4, pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset, batch_size=16, shuffle=False,\n",
        "            num_workers=4, pin_memory=True\n",
        "        )\n",
        "\n",
        "        backbone_params = []\n",
        "        head_params = []\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                if 'head' in name or 'classifier' in name or 'fc' in name:\n",
        "                    head_params.append(param)\n",
        "                else:\n",
        "                    backbone_params.append(param)\n",
        "\n",
        "        optimizer = optim.AdamW([\n",
        "            {'params': backbone_params, 'lr': lr * 0.1},\n",
        "            {'params': head_params, 'lr': lr}\n",
        "        ], weight_decay=0.01)\n",
        "\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=10, T_mult=2, eta_min=lr*0.001\n",
        "        )\n",
        "\n",
        "        criterion = FocalLoss(gamma=1.5, label_smoothing=0.05)\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        patience = 15\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f\"{phase_name} E{epoch+1}/{epochs}\")\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                images, targets_a, targets_b, lam = self.safe_mixup(images, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "\n",
        "                if lam == 1.0:\n",
        "                    loss = criterion(outputs, targets_a)\n",
        "                else:\n",
        "                    loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_acc = val_correct / val_total\n",
        "            train_acc = correct / total\n",
        "\n",
        "            self.log(f\"   E{epoch+1}: Train {train_acc:.4f}, Val {val_acc:.4f}\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), self.results_dir / f\"best_{phase_name}_model.pt\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                self.log(f\"   Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        model.load_state_dict(torch.load(self.results_dir / f\"best_{phase_name}_model.pt\"))\n",
        "\n",
        "        return best_val_acc\n",
        "\n",
        "    def train_kfold_ensemble(self, all_files, all_labels, n_splits=5):\n",
        "        self.log(\"\\nTraining K-Fold Ensemble...\")\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "        fold_models = []\n",
        "\n",
        "        base_models = self.create_models()\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(all_files, all_labels)):\n",
        "            self.log(f\"\\nFold {fold+1}/{n_splits}\")\n",
        "\n",
        "            fold_train_files = [all_files[i] for i in train_idx]\n",
        "            fold_train_labels = [all_labels[i] for i in train_idx]\n",
        "            fold_val_files = [all_files[i] for i in val_idx]\n",
        "            fold_val_labels = [all_labels[i] for i in val_idx]\n",
        "\n",
        "            for model_info in base_models:\n",
        "                model_name = model_info['config']['name']\n",
        "                self.log(f\"\\nTraining {model_name} on Fold {fold+1}\")\n",
        "\n",
        "                model = timm.create_model(\n",
        "                    model_name,\n",
        "                    pretrained=True,\n",
        "                    num_classes=self.num_classes,\n",
        "                    drop_rate=0.4,\n",
        "                    drop_path_rate=0.3\n",
        "                )\n",
        "\n",
        "                trained_model, accuracy = self.train_single_model(\n",
        "                    model,\n",
        "                    fold_train_files, fold_train_labels,\n",
        "                    fold_val_files, fold_val_labels,\n",
        "                    model_name, fold+1\n",
        "                )\n",
        "\n",
        "                fold_models.append({\n",
        "                    'model': trained_model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'name': f\"{model_name}_fold{fold+1}\"\n",
        "                })\n",
        "\n",
        "        return fold_models\n",
        "\n",
        "    def evaluate_with_tta(self, model, test_files, test_labels, img_size=224, n_aug=5):\n",
        "\n",
        "        tta_transforms = [\n",
        "            T.Compose([\n",
        "                ResizeOrPad(img_size),\n",
        "                T.Resize((img_size, img_size)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ]\n",
        "\n",
        "        for i in range(n_aug - 1):\n",
        "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
        "            target_size = max(img_size, img_size + resize_delta)\n",
        "\n",
        "            transform = T.Compose([\n",
        "                ResizeOrPad(target_size + 20),\n",
        "                T.Resize((target_size + 10, target_size + 10)),\n",
        "                T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(\n",
        "                        brightness=random.uniform(0.1, 0.2),\n",
        "                        contrast=random.uniform(0.1, 0.2),\n",
        "                        saturation=random.uniform(0.05, 0.15),\n",
        "                        hue=random.uniform(0.02, 0.05)\n",
        "                    )\n",
        "                ], p=0.8),\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            tta_transforms.append(transform)\n",
        "\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for img_path, label in tqdm(zip(test_files, test_labels), total=len(test_files), desc=\"TTA Evaluation\"):\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "                aug_probs = []\n",
        "                for transform in tta_transforms:\n",
        "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                    output = model(img_tensor)\n",
        "                    probs = F.softmax(output, dim=1)\n",
        "                    aug_probs.append(probs)\n",
        "\n",
        "                weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
        "                weights = weights / weights.sum()\n",
        "\n",
        "                final_probs = torch.zeros_like(aug_probs[0])\n",
        "                for i, probs in enumerate(aug_probs):\n",
        "                    final_probs += probs * weights[i]\n",
        "\n",
        "                conf, pred = torch.max(final_probs, 1)\n",
        "\n",
        "                all_predictions.append(pred.item())\n",
        "                all_labels.append(label)\n",
        "                all_probs.append(final_probs.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        return accuracy, all_predictions, all_labels, all_probs\n",
        "\n",
        "    def ensemble_predict(self, models, test_files, test_labels, use_tta=True):\n",
        "        self.log(\"\\nEnsemble Prediction...\")\n",
        "\n",
        "        all_model_probs = []\n",
        "        model_weights = []\n",
        "\n",
        "        for model_info in models:\n",
        "            model = model_info['model']\n",
        "            accuracy = model_info['accuracy']\n",
        "            name = model_info.get('name', 'model')\n",
        "\n",
        "            self.log(f\"Getting predictions from {name} (acc: {accuracy:.4f})\")\n",
        "\n",
        "            if use_tta:\n",
        "                _, _, _, probs = self.evaluate_with_tta(\n",
        "                    model, test_files, test_labels, n_aug=3\n",
        "                )\n",
        "            else:\n",
        "                model.eval()\n",
        "                probs = []\n",
        "\n",
        "                transform = T.Compose([\n",
        "                    ResizeOrPad(224),\n",
        "                    T.Resize((224, 224)),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for img_path in test_files:\n",
        "                        image = Image.open(img_path).convert('RGB')\n",
        "                        img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "                        output = model(img_tensor)\n",
        "                        prob = F.softmax(output, dim=1).cpu().numpy()\n",
        "                        probs.append(prob)\n",
        "\n",
        "            all_model_probs.append(np.array(probs).squeeze())\n",
        "            model_weights.append(accuracy ** 2)\n",
        "\n",
        "        model_weights = np.array(model_weights)\n",
        "        model_weights = model_weights / model_weights.sum()\n",
        "\n",
        "        final_probs = np.zeros_like(all_model_probs[0])\n",
        "        for i, probs in enumerate(all_model_probs):\n",
        "            final_probs += probs * model_weights[i]\n",
        "\n",
        "        predictions = np.argmax(final_probs, axis=1)\n",
        "        accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "        return accuracy, predictions, final_probs\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        try:\n",
        "            train_files, train_labels, test_files, test_labels = self.collect_dataset()\n",
        "            all_files = train_files + test_files\n",
        "            all_labels = train_labels + test_labels\n",
        "\n",
        "            fold_models = self.train_kfold_ensemble(all_files, all_labels, n_splits=5)\n",
        "\n",
        "            self.log(\"\\nTraining additional models on full training set...\")\n",
        "            full_models = self.create_models()\n",
        "\n",
        "            for model_info in full_models:\n",
        "                model_name = model_info['config']['name']\n",
        "                self.log(f\"\\nTraining {model_name} on full train set\")\n",
        "\n",
        "                trained_model, accuracy = self.train_single_model(\n",
        "                    model_info['model'],\n",
        "                    train_files, train_labels,\n",
        "                    test_files, test_labels,\n",
        "                    model_name\n",
        "                )\n",
        "\n",
        "                fold_models.append({\n",
        "                    'model': trained_model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'name': f\"{model_name}_full\"\n",
        "                })\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"INDIVIDUAL MODEL RESULTS WITH TTA:\")\n",
        "\n",
        "            best_single_acc = 0\n",
        "            for model_info in fold_models:\n",
        "                tta_acc, _, _, _ = self.evaluate_with_tta(\n",
        "                    model_info['model'], test_files, test_labels, n_aug=5\n",
        "                )\n",
        "                self.log(f\"{model_info['name']}: {tta_acc:.4f} ({tta_acc*100:.2f}%)\")\n",
        "\n",
        "                if tta_acc > best_single_acc:\n",
        "                    best_single_acc = tta_acc\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"ENSEMBLE RESULTS:\")\n",
        "\n",
        "            fold_models.sort(key=lambda x: x['accuracy'], reverse=True)\n",
        "            top_models = fold_models[:7]\n",
        "\n",
        "            ensemble_acc, _, _ = self.ensemble_predict(\n",
        "                top_models, test_files, test_labels, use_tta=False\n",
        "            )\n",
        "            self.log(f\"Ensemble (no TTA): {ensemble_acc:.4f} ({ensemble_acc*100:.2f}%)\")\n",
        "\n",
        "            ensemble_tta_acc, predictions, probs = self.ensemble_predict(\n",
        "                top_models, test_files, test_labels, use_tta=True\n",
        "            )\n",
        "            self.log(f\"Ensemble with TTA: {ensemble_tta_acc:.4f} ({ensemble_tta_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"DETAILED CLASSIFICATION REPORT:\")\n",
        "\n",
        "            report = classification_report(\n",
        "                test_labels, predictions,\n",
        "                target_names=self.class_names,\n",
        "                digits=4\n",
        "            )\n",
        "            self.log(report)\n",
        "\n",
        "            cm = confusion_matrix(test_labels, predictions)\n",
        "            self.log(\"\\nConfusion Matrix:\")\n",
        "            self.log(str(cm))\n",
        "\n",
        "            self.log(\"\\nPer-class Accuracy:\")\n",
        "            for i, class_name in enumerate(self.class_names):\n",
        "                class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
        "                self.log(f\"   {class_name}: {class_acc:.4f} ({class_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*80)\n",
        "            self.log(\"FINAL RESULTS:\")\n",
        "            self.log(f\"Best Single Model with TTA: {best_single_acc:.4f} ({best_single_acc*100:.2f}%)\")\n",
        "            self.log(f\"Ensemble with TTA: {ensemble_tta_acc:.4f} ({ensemble_tta_acc*100:.2f}%)\")\n",
        "\n",
        "            final_accuracy = max(best_single_acc, ensemble_tta_acc)\n",
        "\n",
        "            self.log(\"\\nSaving models...\")\n",
        "            ensemble_info = {\n",
        "                'models': [m['name'] for m in top_models],\n",
        "                'weights': [m['accuracy'] for m in top_models],\n",
        "                'final_accuracy': ensemble_tta_acc,\n",
        "                'class_names': self.class_names\n",
        "            }\n",
        "\n",
        "            import pickle\n",
        "            with open(self.results_dir / 'ensemble_info.pkl', 'wb') as f:\n",
        "                pickle.dump(ensemble_info, f)\n",
        "\n",
        "            for i, model_info in enumerate(top_models):\n",
        "                torch.save(\n",
        "                    model_info['model'].state_dict(),\n",
        "                    self.results_dir / f\"ensemble_model_{i}.pt\"\n",
        "                )\n",
        "\n",
        "            self.log(f\"\\nResults saved to: {self.results_dir}\")\n",
        "\n",
        "            return {\n",
        "                'final_accuracy': final_accuracy,\n",
        "                'ensemble_accuracy': ensemble_tta_acc,\n",
        "                'best_single_accuracy': best_single_acc,\n",
        "                'num_models': len(top_models)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log(f\"Error: {e}\")\n",
        "            import traceback\n",
        "            self.log(traceback.format_exc())\n",
        "            return None"
      ],
      "metadata": {
        "id": "bm_pe5nROY7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/kaggle/working/data_cifar10_style_public\"\n",
        "classifier = EndoscopyClassifier(data_path, test_size=0.2)\n",
        "\n",
        "results = classifier.run_pipeline()"
      ],
      "metadata": {
        "id": "BxCMtkDcPYOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline cải tiến"
      ],
      "metadata": {
        "id": "pZZUex7_Pdq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1I56vd3aWsy_nkY6zdXk4faIM6NSS5mer"
      ],
      "metadata": {
        "id": "eGMzu8KrPf9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /kaggle/working/data_cifar10_style_public.zip"
      ],
      "metadata": {
        "id": "pPhRbdX-PnEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import timm\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "ASsUnekQPotZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "    PEFT_AVAILABLE = True\n",
        "    print(\"PEFT library available - using official LoRA implementation\")\n",
        "except ImportError:\n",
        "    PEFT_AVAILABLE = False\n",
        "    print(\"PEFT library not available. Install with: pip install peft\")\n",
        "    print(\"Falling back to custom LoRA implementation\")\n",
        "\n",
        "def count_peft_parameters(model):\n",
        "    try:\n",
        "        if hasattr(model, 'print_trainable_parameters') and model.use_peft:\n",
        "            print(\"PEFT trainable parameters:\")\n",
        "            model.print_trainable_parameters()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not print PEFT parameters: {e}\")\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    frozen_params = total_params - trainable_params\n",
        "\n",
        "    return {\n",
        "        'total': total_params,\n",
        "        'trainable': trainable_params,\n",
        "        'frozen': frozen_params,\n",
        "        'trainable_percentage': (trainable_params / total_params) * 100\n",
        "    }"
      ],
      "metadata": {
        "id": "57NQoTRwPtD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.02):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean"
      ],
      "metadata": {
        "id": "Vhd7qR17PxqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimulateEndoscopeLighting:\n",
        "    def __init__(self, severity=0.3):\n",
        "        self.severity = severity\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_array = np.array(img).astype(np.float32)\n",
        "        h, w = img_array.shape[:2]\n",
        "\n",
        "        center_x, center_y = w // 2, h // 2\n",
        "        Y, X = np.ogrid[:h, :w]\n",
        "        dist = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n",
        "        max_dist = np.sqrt(center_x**2 + center_y**2)\n",
        "        mask = 1 - (dist / max_dist) * self.severity\n",
        "\n",
        "        for c in range(3):\n",
        "            img_array[:, :, c] *= mask\n",
        "\n",
        "        return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))"
      ],
      "metadata": {
        "id": "-CdP_9I2Pz6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeOrPad:\n",
        "    def __init__(self, min_size):\n",
        "        self.min_size = min_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if w < self.min_size or h < self.min_size:\n",
        "            scale = self.min_size / min(w, h)\n",
        "            new_w = int(w * scale)\n",
        "            new_h = int(h * scale)\n",
        "            return T.functional.resize(img, (new_h, new_w))\n",
        "        return img"
      ],
      "metadata": {
        "id": "1pZM1ju7P3Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.5, label_smoothing=0.05):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        n_classes = inputs.size(-1)\n",
        "        device = inputs.device\n",
        "\n",
        "        targets_one_hot = F.one_hot(targets, n_classes).float()\n",
        "        targets_smooth = targets_one_hot * (1 - self.label_smoothing) + self.label_smoothing / n_classes\n",
        "\n",
        "        p = F.softmax(inputs, dim=-1)\n",
        "        ce_loss = -targets_smooth * torch.log(p + 1e-8)\n",
        "        p_t = p.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
        "        focal_weight = (1 - p_t).pow(self.gamma)\n",
        "\n",
        "        focal_loss = focal_weight.unsqueeze(1) * ce_loss\n",
        "        return focal_loss.sum(dim=1).mean()"
      ],
      "metadata": {
        "id": "vM_G1BEmP6SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnatomicalGroupAuxiliaryModel(nn.Module):\n",
        "    \"\"\"Multi-Head Model với Primary Head và Auxiliary Head + PEFT\"\"\"\n",
        "\n",
        "    def __init__(self, backbone_name, num_classes=7, num_groups=4, drop_rate=0.4, drop_path_rate=0.3,\n",
        "                 use_peft=True, lora_rank=16, lora_alpha=32, lora_dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.use_peft = use_peft and PEFT_AVAILABLE\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            backbone_name,\n",
        "            pretrained=True,\n",
        "            num_classes=0,\n",
        "            drop_rate=drop_rate,\n",
        "            drop_path_rate=drop_path_rate\n",
        "        )\n",
        "\n",
        "        feature_dim = self.backbone.num_features\n",
        "\n",
        "        # Primary Head\n",
        "        self.primary_head = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(feature_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        # Auxiliary Head\n",
        "        self.auxiliary_head = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(feature_dim, num_groups)\n",
        "        )\n",
        "\n",
        "        if self.use_peft:\n",
        "            self._apply_peft(lora_rank, lora_alpha, lora_dropout)\n",
        "\n",
        "    def _apply_peft(self, rank=16, alpha=32, dropout=0.1):\n",
        "\n",
        "        if not PEFT_AVAILABLE:\n",
        "            print(\"PEFT not available, skipping...\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            target_modules = self._find_target_modules()\n",
        "\n",
        "            if not target_modules:\n",
        "                print(\"No suitable target modules found for PEFT, using custom LoRA\")\n",
        "                self.use_peft = False\n",
        "                self._apply_custom_lora(rank, alpha, dropout)\n",
        "                return\n",
        "\n",
        "            peft_config = LoraConfig(\n",
        "                inference_mode=False,\n",
        "                r=rank,\n",
        "                lora_alpha=alpha,\n",
        "                lora_dropout=dropout,\n",
        "                target_modules=target_modules,\n",
        "                modules_to_save=[],\n",
        "                bias=\"none\",\n",
        "            )\n",
        "\n",
        "            # Wrap backbone with PEFT\n",
        "            self.backbone = get_peft_model(self.backbone, peft_config)\n",
        "            print(f\"Applied PEFT LoRA to backbone with rank={rank}, alpha={alpha}\")\n",
        "            print(f\"Target modules: {target_modules}\")\n",
        "\n",
        "            if hasattr(self.backbone, 'print_trainable_parameters'):\n",
        "                print(\"PEFT Parameter Summary:\")\n",
        "                self.backbone.print_trainable_parameters()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to apply PEFT: {e}\")\n",
        "            print(\"Falling back to custom LoRA implementation...\")\n",
        "            self.use_peft = False\n",
        "            self._apply_custom_lora(rank, alpha, dropout)\n",
        "\n",
        "    def _find_target_modules(self):\n",
        "        target_modules = []\n",
        "\n",
        "        # Walk through the model and find Linear layers\n",
        "        for name, module in self.backbone.named_modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                # Skip very small layers and heads\n",
        "                if module.in_features >= 64 and module.out_features >= 64:\n",
        "                    # Extract the module name (last part)\n",
        "                    module_name = name.split('.')[-1]\n",
        "                    if module_name not in target_modules:\n",
        "                        target_modules.append(module_name)\n",
        "\n",
        "        if not target_modules:\n",
        "            potential_targets = [\n",
        "                \"pwconv1\", \"pwconv2\",  # ConvNeXt\n",
        "                \"fc1\", \"fc2\",          # MLP blocks\n",
        "                \"qkv\", \"proj\",         # Attention (if any)\n",
        "                \"linear\"               # Generic linear\n",
        "            ]\n",
        "\n",
        "            for target in potential_targets:\n",
        "                for name, module in self.backbone.named_modules():\n",
        "                    if target in name and isinstance(module, nn.Linear):\n",
        "                        if module.in_features >= 64:\n",
        "                            target_modules.append(target)\n",
        "                            break\n",
        "\n",
        "        return list(set(target_modules))  # Remove duplicates\n",
        "\n",
        "    def _apply_custom_lora(self, rank=16, alpha=32, dropout=0.1):\n",
        "        print(\"Applying custom LoRA implementation...\")\n",
        "\n",
        "        def apply_lora_to_linear(module, name=\"\"):\n",
        "            for child_name, child_module in module.named_children():\n",
        "                full_name = f\"{name}.{child_name}\" if name else child_name\n",
        "\n",
        "                if isinstance(child_module, nn.Linear) and child_module.in_features >= 64:\n",
        "                    lora_layer = self._create_lora_layer(child_module, rank, alpha, dropout)\n",
        "                    setattr(module, child_name, lora_layer)\n",
        "                    print(f\"Applied custom LoRA to: {full_name}\")\n",
        "                else:\n",
        "                    apply_lora_to_linear(child_module, full_name)\n",
        "\n",
        "        apply_lora_to_linear(self.backbone, \"backbone\")\n",
        "\n",
        "    def _create_lora_layer(self, original_layer, rank, alpha, dropout):\n",
        "        class CustomLoRALayer(nn.Module):\n",
        "            def __init__(self, original_layer, rank, alpha, dropout):\n",
        "                super().__init__()\n",
        "                self.original_layer = original_layer\n",
        "                self.rank = rank\n",
        "                self.alpha = alpha\n",
        "\n",
        "                # Freeze original weights\n",
        "                for param in self.original_layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "                # LoRA matrices\n",
        "                in_features = original_layer.in_features\n",
        "                out_features = original_layer.out_features\n",
        "\n",
        "                self.lora_A = nn.Linear(in_features, rank, bias=False)\n",
        "                self.lora_B = nn.Linear(rank, out_features, bias=False)\n",
        "                self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "                # Initialize\n",
        "                nn.init.normal_(self.lora_A.weight, std=1/rank)\n",
        "                nn.init.zeros_(self.lora_B.weight)\n",
        "\n",
        "                self.scaling = alpha / rank\n",
        "\n",
        "            def forward(self, x):\n",
        "                original_output = self.original_layer(x)\n",
        "                lora_output = self.lora_B(self.lora_A(self.dropout(x)))\n",
        "                return original_output + lora_output * self.scaling\n",
        "\n",
        "        return CustomLoRALayer(original_layer, rank, alpha, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        primary_logits = self.primary_head(features)      # 7 lớp\n",
        "        auxiliary_logits = self.auxiliary_head(features)  # 4 nhóm\n",
        "\n",
        "        return primary_logits, auxiliary_logits\n",
        "\n",
        "    def save_peft_model(self, save_directory):\n",
        "        if self.use_peft and hasattr(self.backbone, 'save_pretrained'):\n",
        "            try:\n",
        "                self.backbone.save_pretrained(save_directory)\n",
        "                print(f\"PEFT adapters saved to {save_directory}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to save PEFT adapters: {e}\")\n",
        "        else:\n",
        "            print(\"No PEFT model to save or using custom LoRA\")\n",
        "\n",
        "    def load_peft_model(self, save_directory):\n",
        "        if self.use_peft:\n",
        "            try:\n",
        "                self.backbone = PeftModel.from_pretrained(self.backbone, save_directory)\n",
        "                print(f\"PEFT adapters loaded from {save_directory}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load PEFT adapters: {e}\")"
      ],
      "metadata": {
        "id": "HL_aHgGsQBOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnatomicalGroupAuxiliaryLoss(nn.Module):\n",
        "    def __init__(self, class_to_group_mapping, gamma=1.5, label_smoothing=0.05, lambda_aux=0.4):\n",
        "        super().__init__()\n",
        "        self.class_to_group = class_to_group_mapping\n",
        "        self.lambda_aux = lambda_aux\n",
        "\n",
        "        # Primary loss: Focal Loss cho 7 lớp\n",
        "        self.focal_loss = FocalLoss(gamma=gamma, label_smoothing=label_smoothing)\n",
        "\n",
        "        # Auxiliary loss: Cross-Entropy cho 4 nhóm\n",
        "        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "    def forward(self, primary_logits, auxiliary_logits, labels):\n",
        "        primary_loss = self.focal_loss(primary_logits, labels)\n",
        "\n",
        "        group_labels = torch.tensor([self.class_to_group[label.item()] for label in labels]).to(labels.device)\n",
        "\n",
        "        auxiliary_loss = self.ce_loss(auxiliary_logits, group_labels)\n",
        "\n",
        "        # L_total = L_primary + λ * L_auxiliary\n",
        "        total_loss = primary_loss + self.lambda_aux * auxiliary_loss\n",
        "\n",
        "        return total_loss, primary_loss, auxiliary_loss"
      ],
      "metadata": {
        "id": "KxTattpRQaqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None, class_to_group_mapping=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.class_to_group = class_to_group_mapping\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "FZ8vOF1LQoAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EndoscopyClassifierWithPEFT:\n",
        "    def __init__(self, data_path, project_name=\"anatomical_peft_classifier\", test_size=0.2,\n",
        "                 use_peft=True, lora_rank=16, lora_alpha=32):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.project_name = project_name\n",
        "        self.test_size = test_size\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.use_peft = use_peft and PEFT_AVAILABLE\n",
        "        self.lora_rank = lora_rank\n",
        "        self.lora_alpha = lora_alpha\n",
        "\n",
        "        self.results_dir = Path(f\"results_{project_name}\")\n",
        "        self.results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        self.setup_logging()\n",
        "\n",
        "        self.class_names = [\n",
        "            \"nose-right\",  # 0\n",
        "            \"nose-left\",   # 1\n",
        "            \"ear-right\",   # 2\n",
        "            \"ear-left\",    # 3\n",
        "            \"vc-open\",     # 4\n",
        "            \"vc-closed\",   # 5\n",
        "            \"throat\"       # 6\n",
        "        ]\n",
        "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
        "        self.idx_to_class = {idx: name for name, idx in self.class_to_idx.items()}\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "        self.class_to_anatomical_group = {\n",
        "            0: 0,  # nose-right -> Nose\n",
        "            1: 0,  # nose-left -> Nose\n",
        "            2: 1,  # ear-right -> Ear\n",
        "            3: 1,  # ear-left -> Ear\n",
        "            4: 2,  # vc-open -> Vocal Cords\n",
        "            5: 2,  # vc-closed -> Vocal Cords\n",
        "            6: 3   # throat -> Throat\n",
        "        }\n",
        "\n",
        "        self.anatomical_group_names = [\"Nose\", \"Ear\", \"Vocal_Cords\", \"Throat\"]\n",
        "        self.num_groups = len(self.anatomical_group_names)\n",
        "\n",
        "        self.left_classes = [1, 3]  # nose-left, ear-left\n",
        "        self.right_classes = [0, 2]  # nose-right, ear-right\n",
        "        self.other_classes = [4, 5, 6]  # vc-open, vc-closed, throat\n",
        "\n",
        "        self.log(f\"PEFT Available: {PEFT_AVAILABLE}\")\n",
        "        self.log(f\"PEFT Enabled: {use_peft}\")\n",
        "        if self.use_peft:\n",
        "            self.log(f\"LoRA Config: rank={lora_rank}, alpha={lora_alpha}\")\n",
        "        self.log(f\"Anatomical Groups: {self.anatomical_group_names}\")\n",
        "        self.log(\"Device: {}\".format(self.device))\n",
        "\n",
        "    def setup_logging(self):\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.log_file = self.results_dir / f\"log_{timestamp}.txt\"\n",
        "\n",
        "        def log_print(*args, **kwargs):\n",
        "            message = \" \".join(str(arg) for arg in args)\n",
        "            print(message, **kwargs)\n",
        "            with open(self.log_file, 'a', encoding='utf-8') as f:\n",
        "                f.write(f\"[{datetime.now().strftime('%H:%M:%S')}] {message}\\n\")\n",
        "\n",
        "        self.log = log_print\n",
        "\n",
        "    def collect_dataset(self):\n",
        "        self.log(\"Collecting dataset...\")\n",
        "\n",
        "        all_files = []\n",
        "        all_labels = []\n",
        "\n",
        "        for idx, class_name in enumerate(self.class_names):\n",
        "            class_dir = self.data_path / class_name\n",
        "            if class_dir.exists():\n",
        "                images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
        "                all_files.extend([str(img) for img in images])\n",
        "                all_labels.extend([idx] * len(images))\n",
        "                group_name = self.anatomical_group_names[self.class_to_anatomical_group[idx]]\n",
        "                self.log(f\" {class_name} (Group: {group_name}): {len(images)} images\")\n",
        "\n",
        "        train_files, test_files, train_labels, test_labels = train_test_split(\n",
        "            all_files, all_labels,\n",
        "            test_size=self.test_size,\n",
        "            stratify=all_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.log(f\"Total: {len(all_files)} images\")\n",
        "        self.log(f\"Train: {len(train_files)}, Test: {len(test_files)}\")\n",
        "\n",
        "        return train_files, train_labels, test_files, test_labels\n",
        "\n",
        "    def setup_safe_augmentation(self, img_size=224, phase=\"moderate\"):\n",
        "        if phase == \"gentle\":\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 10),\n",
        "                T.Resize((img_size + 10, img_size + 10)),\n",
        "                T.CenterCrop(img_size),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "        elif phase == \"moderate\":\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 30),\n",
        "                T.Resize((img_size + 20, img_size + 20)),\n",
        "                T.RandomCrop(img_size),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.05)\n",
        "                ], p=0.8),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    SimulateEndoscopeLighting(severity=0.3)\n",
        "                ], p=0.3),\n",
        "\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=2.0),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=0.5),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                AddGaussianNoise(std=0.01),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                T.RandomErasing(p=0.15, scale=(0.02, 0.12))\n",
        "            ])\n",
        "\n",
        "        else:\n",
        "            train_transform = T.Compose([\n",
        "                ResizeOrPad(img_size + 40),\n",
        "                T.RandomChoice([\n",
        "                    T.Compose([T.Resize((img_size + 40, img_size + 40)), T.CenterCrop(img_size)]),\n",
        "                    T.Compose([T.Resize((img_size + 20, img_size + 20)), T.CenterCrop(img_size)]),\n",
        "                    T.Compose([T.Resize((img_size, img_size))]),\n",
        "                    T.Compose([T.Resize((img_size + 32, img_size + 32)), T.RandomCrop(img_size)]),\n",
        "                ]),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.08)\n",
        "                ], p=0.9),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    SimulateEndoscopeLighting(severity=random.uniform(0.2, 0.4))\n",
        "                ], p=0.5),\n",
        "\n",
        "                T.RandomApply([\n",
        "                    T.RandomAutocontrast(),\n",
        "                    T.RandomEqualize(),\n",
        "                ], p=0.3),\n",
        "\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
        "                    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=0.3),\n",
        "                    T.RandomAdjustSharpness(sharpness_factor=3.0),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "\n",
        "                T.ToTensor(),\n",
        "                AddGaussianNoise(std=0.02),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                T.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.5, 2.0))\n",
        "            ])\n",
        "\n",
        "        val_transform = T.Compose([\n",
        "            ResizeOrPad(img_size),\n",
        "            T.Resize((img_size, img_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        return train_transform, val_transform\n",
        "\n",
        "    def safe_mixup(self, x, y, alpha=0.2):\n",
        "        if np.random.rand() > 0.5:\n",
        "            return x, y, y, 1.0\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        indices = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            current_class = y[i].item()\n",
        "\n",
        "            if current_class in self.left_classes:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.left_classes and j != i]\n",
        "            elif current_class in self.right_classes:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.right_classes and j != i]\n",
        "            else:\n",
        "                valid_indices = [j for j in range(batch_size) if y[j].item() in self.other_classes and j != i]\n",
        "\n",
        "            if valid_indices:\n",
        "                idx = np.random.choice(valid_indices)\n",
        "            else:\n",
        "                idx = i\n",
        "            indices.append(idx)\n",
        "\n",
        "        indices = torch.tensor(indices).to(x.device)\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        lam = max(lam, 1 - lam)\n",
        "\n",
        "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
        "        return mixed_x, y, y[indices], lam\n",
        "\n",
        "    def create_anatomical_peft_models(self):\n",
        "        models_config = [\n",
        "            {\"name\": \"convnext_small.fb_in22k_ft_in1k\", \"img_size\": 224},\n",
        "        ]\n",
        "\n",
        "        models = []\n",
        "        for config in models_config:\n",
        "            try:\n",
        "                model = AnatomicalGroupAuxiliaryModel(\n",
        "                    backbone_name=config['name'],\n",
        "                    num_classes=self.num_classes,\n",
        "                    num_groups=self.num_groups,\n",
        "                    drop_rate=0.4,\n",
        "                    drop_path_rate=0.3,\n",
        "                    use_peft=self.use_peft,\n",
        "                    lora_rank=self.lora_rank,\n",
        "                    lora_alpha=self.lora_alpha,\n",
        "                    lora_dropout=0.1\n",
        "                )\n",
        "\n",
        "                param_info = count_peft_parameters(model)\n",
        "                self.log(f\"Created Anatomical Multi-Head + PEFT: {config['name']}\")\n",
        "                self.log(f\"  Total params: {param_info['total']:,}\")\n",
        "                self.log(f\"  Trainable params: {param_info['trainable']:,} ({param_info['trainable_percentage']:.2f}%)\")\n",
        "                self.log(f\"  Frozen params: {param_info['frozen']:,}\")\n",
        "\n",
        "                models.append({'model': model, 'config': config})\n",
        "\n",
        "            except Exception as e:\n",
        "                self.log(f\"Failed: {config['name']} - {e}\")\n",
        "\n",
        "        return models\n",
        "\n",
        "    def train_single_model(self, model, train_files, train_labels, val_files, val_labels,\n",
        "                          model_name, fold=None):\n",
        "        model = model.to(self.device)\n",
        "        img_size = 224\n",
        "        best_acc = 0.0\n",
        "\n",
        "        self.log(f\"\\nTraining with PEFT for {model_name}\" + (f\" (Fold {fold})\" if fold else \"\"))\n",
        "\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        self.log(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
        "\n",
        "        self.log(f\"\\nPhase 1: PEFT training for {model_name}\")\n",
        "\n",
        "        train_transform, val_transform = self.setup_safe_augmentation(img_size, \"gentle\")\n",
        "        train_dataset = EarDataset(train_files, train_labels, train_transform, self.class_to_anatomical_group)\n",
        "        val_dataset = EarDataset(val_files, val_labels, val_transform, self.class_to_anatomical_group)\n",
        "\n",
        "        phase1_acc = self.train_phase(\n",
        "            model, train_dataset, val_dataset,\n",
        "            epochs=25, lr=2e-3, phase_name=\"peft_gentle\", lambda_aux=0.4\n",
        "        )\n",
        "\n",
        "        if phase1_acc > best_acc:\n",
        "            best_acc = phase1_acc\n",
        "\n",
        "        self.log(f\"\\nPhase 2: PEFT training for {model_name}\")\n",
        "\n",
        "        train_transform, val_transform = self.setup_safe_augmentation(img_size, \"moderate\")\n",
        "        train_dataset = EarDataset(train_files, train_labels, train_transform, self.class_to_anatomical_group)\n",
        "        val_dataset = EarDataset(val_files, val_labels, val_transform, self.class_to_anatomical_group)\n",
        "\n",
        "        phase2_acc = self.train_phase(\n",
        "            model, train_dataset, val_dataset,\n",
        "            epochs=35, lr=1e-3, phase_name=\"peft_moderate\", lambda_aux=0.4\n",
        "        )\n",
        "\n",
        "        if phase2_acc > best_acc:\n",
        "            best_acc = phase2_acc\n",
        "\n",
        "        if best_acc < 0.92:\n",
        "            self.log(f\"\\nPhase 3: PEFT training for {model_name}\")\n",
        "\n",
        "            train_transform, val_transform = self.setup_safe_augmentation(img_size, \"strong\")\n",
        "            train_dataset = EarDataset(train_files, train_labels, train_transform, self.class_to_anatomical_group)\n",
        "            val_dataset = EarDataset(val_files, val_labels, val_transform, self.class_to_anatomical_group)\n",
        "\n",
        "            phase3_acc = self.train_phase(\n",
        "                model, train_dataset, val_dataset,\n",
        "                epochs=30, lr=5e-4, phase_name=\"peft_strong\", lambda_aux=0.3\n",
        "            )\n",
        "\n",
        "            if phase3_acc > best_acc:\n",
        "                best_acc = phase3_acc\n",
        "\n",
        "        return model, best_acc\n",
        "\n",
        "    def train_phase(self, model, train_dataset, val_dataset, epochs, lr, phase_name, lambda_aux=0.4):\n",
        "        class_counts = np.bincount(train_dataset.labels)\n",
        "        weights = 1.0 / class_counts[train_dataset.labels]\n",
        "        sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset, batch_size=16, sampler=sampler,\n",
        "            num_workers=4, pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset, batch_size=16, shuffle=False,\n",
        "            num_workers=4, pin_memory=True\n",
        "        )\n",
        "\n",
        "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "        optimizer = optim.AdamW(trainable_params, lr=lr, weight_decay=0.01)\n",
        "\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=10, T_mult=2, eta_min=lr*0.001\n",
        "        )\n",
        "\n",
        "        criterion = AnatomicalGroupAuxiliaryLoss(\n",
        "            class_to_group_mapping=self.class_to_anatomical_group,\n",
        "            gamma=1.5,\n",
        "            label_smoothing=0.05,\n",
        "            lambda_aux=lambda_aux\n",
        "        )\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        patience = 15\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            total_primary_loss = 0.0\n",
        "            total_auxiliary_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f\"{phase_name} E{epoch+1}/{epochs}\")\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                # Safe MixUp\n",
        "                images, targets_a, targets_b, lam = self.safe_mixup(images, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                primary_outputs, auxiliary_outputs = model(images)\n",
        "\n",
        "                if lam == 1.0:\n",
        "                    total_loss, primary_loss, auxiliary_loss = criterion(\n",
        "                        primary_outputs, auxiliary_outputs, targets_a\n",
        "                    )\n",
        "                else:\n",
        "                    total_loss_a, primary_loss_a, auxiliary_loss_a = criterion(\n",
        "                        primary_outputs, auxiliary_outputs, targets_a\n",
        "                    )\n",
        "                    total_loss_b, primary_loss_b, auxiliary_loss_b = criterion(\n",
        "                        primary_outputs, auxiliary_outputs, targets_b\n",
        "                    )\n",
        "\n",
        "                    total_loss = lam * total_loss_a + (1 - lam) * total_loss_b\n",
        "                    primary_loss = lam * primary_loss_a + (1 - lam) * primary_loss_b\n",
        "                    auxiliary_loss = lam * auxiliary_loss_a + (1 - lam) * auxiliary_loss_b\n",
        "\n",
        "                total_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += total_loss.item()\n",
        "                total_primary_loss += primary_loss.item()\n",
        "                total_auxiliary_loss += auxiliary_loss.item()\n",
        "\n",
        "                _, predicted = torch.max(primary_outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{total_loss.item():.4f}',\n",
        "                    'primary': f'{primary_loss.item():.4f}',\n",
        "                    'aux': f'{auxiliary_loss.item():.4f}'\n",
        "                })\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            val_primary_correct = 0\n",
        "            val_auxiliary_correct = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                    primary_outputs, auxiliary_outputs = model(images)\n",
        "\n",
        "                    _, primary_predicted = torch.max(primary_outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_primary_correct += (primary_predicted == labels).sum().item()\n",
        "\n",
        "                    group_labels = torch.tensor([self.class_to_anatomical_group[label.item()] for label in labels]).to(labels.device)\n",
        "                    _, auxiliary_predicted = torch.max(auxiliary_outputs.data, 1)\n",
        "                    val_auxiliary_correct += (auxiliary_predicted == group_labels).sum().item()\n",
        "\n",
        "            val_primary_acc = val_primary_correct / val_total\n",
        "            val_auxiliary_acc = val_auxiliary_correct / val_total\n",
        "            train_acc = correct / total\n",
        "\n",
        "            self.log(f\" E{epoch+1}: Train {train_acc:.4f}, Val_Primary {val_primary_acc:.4f}, Val_Auxiliary {val_auxiliary_acc:.4f}\")\n",
        "            self.log(f\"   Losses - Total: {train_loss/len(train_loader):.4f}, Primary: {total_primary_loss/len(train_loader):.4f}, Aux: {total_auxiliary_loss/len(train_loader):.4f}\")\n",
        "\n",
        "            if val_primary_acc > best_val_acc:\n",
        "                best_val_acc = val_primary_acc\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), self.results_dir / f\"best_{phase_name}_model.pt\")\n",
        "\n",
        "                if model.use_peft:\n",
        "                    peft_save_dir = self.results_dir / f\"peft_{phase_name}\"\n",
        "                    peft_save_dir.mkdir(exist_ok=True)\n",
        "                    model.save_peft_model(str(peft_save_dir))\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                self.log(f\" Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        model.load_state_dict(torch.load(self.results_dir / f\"best_{phase_name}_model.pt\"))\n",
        "\n",
        "        return best_val_acc\n",
        "\n",
        "    def train_kfold_ensemble(self, all_files, all_labels, n_splits=5):\n",
        "        self.log(\"\\nTraining K-Fold Ensemble với Anatomical Group Auxiliary Loss + PEFT...\")\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "        fold_models = []\n",
        "\n",
        "        base_models = self.create_anatomical_peft_models()\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(all_files, all_labels)):\n",
        "            self.log(f\"\\nFold {fold+1}/{n_splits}\")\n",
        "\n",
        "            fold_train_files = [all_files[i] for i in train_idx]\n",
        "            fold_train_labels = [all_labels[i] for i in train_idx]\n",
        "            fold_val_files = [all_files[i] for i in val_idx]\n",
        "            fold_val_labels = [all_labels[i] for i in val_idx]\n",
        "\n",
        "            for model_info in base_models:\n",
        "                model_name = model_info['config']['name']\n",
        "                self.log(f\"\\nTraining {model_name} on Fold {fold+1}\")\n",
        "\n",
        "                model = AnatomicalGroupAuxiliaryModel(\n",
        "                    backbone_name=model_name,\n",
        "                    num_classes=self.num_classes,\n",
        "                    num_groups=self.num_groups,\n",
        "                    drop_rate=0.4,\n",
        "                    drop_path_rate=0.3,\n",
        "                    use_peft=self.use_peft,\n",
        "                    lora_rank=self.lora_rank,\n",
        "                    lora_alpha=self.lora_alpha,\n",
        "                    lora_dropout=0.1\n",
        "                )\n",
        "\n",
        "                trained_model, accuracy = self.train_single_model(\n",
        "                    model,\n",
        "                    fold_train_files, fold_train_labels,\n",
        "                    fold_val_files, fold_val_labels,\n",
        "                    model_name, fold+1\n",
        "                )\n",
        "\n",
        "                fold_models.append({\n",
        "                    'model': trained_model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'name': f\"{model_name}_fold{fold+1}\"\n",
        "                })\n",
        "\n",
        "        return fold_models\n",
        "\n",
        "    def evaluate_with_tta(self, model, test_files, test_labels, img_size=224, n_aug=5):\n",
        "        tta_transforms = [\n",
        "            T.Compose([\n",
        "                ResizeOrPad(img_size),\n",
        "                T.Resize((img_size, img_size)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        ]\n",
        "\n",
        "        for i in range(n_aug - 1):\n",
        "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
        "            target_size = max(img_size, img_size + resize_delta)\n",
        "\n",
        "            transform = T.Compose([\n",
        "                ResizeOrPad(target_size + 20),\n",
        "                T.Resize((target_size + 10, target_size + 10)),\n",
        "                T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
        "                T.RandomApply([\n",
        "                    T.ColorJitter(\n",
        "                        brightness=random.uniform(0.1, 0.2),\n",
        "                        contrast=random.uniform(0.1, 0.2),\n",
        "                        saturation=random.uniform(0.05, 0.15),\n",
        "                        hue=random.uniform(0.02, 0.05)\n",
        "                    )\n",
        "                ], p=0.8),\n",
        "                T.RandomChoice([\n",
        "                    T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
        "                    nn.Identity()\n",
        "                ]),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "            tta_transforms.append(transform)\n",
        "\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for img_path, label in tqdm(zip(test_files, test_labels), total=len(test_files), desc=\"TTA Evaluation\"):\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "                aug_probs = []\n",
        "                for transform in tta_transforms:\n",
        "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "                    primary_output, _ = model(img_tensor)\n",
        "                    probs = F.softmax(primary_output, dim=1)\n",
        "                    aug_probs.append(probs)\n",
        "\n",
        "                weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
        "                weights = weights / weights.sum()\n",
        "\n",
        "                final_probs = torch.zeros_like(aug_probs[0])\n",
        "                for i, probs in enumerate(aug_probs):\n",
        "                    final_probs += probs * weights[i]\n",
        "\n",
        "                conf, pred = torch.max(final_probs, 1)\n",
        "\n",
        "                all_predictions.append(pred.item())\n",
        "                all_labels.append(label)\n",
        "                all_probs.append(final_probs.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        return accuracy, all_predictions, all_labels, all_probs\n",
        "\n",
        "    def ensemble_predict(self, models, test_files, test_labels, use_tta=True):\n",
        "        self.log(\"\\nEnsemble Prediction với Anatomical Group Auxiliary + PEFT Models...\")\n",
        "\n",
        "        all_model_probs = []\n",
        "        model_weights = []\n",
        "\n",
        "        for model_info in models:\n",
        "            model = model_info['model']\n",
        "            accuracy = model_info['accuracy']\n",
        "            name = model_info.get('name', 'model')\n",
        "\n",
        "            self.log(f\"Getting predictions from {name} (acc: {accuracy:.4f})\")\n",
        "\n",
        "            if use_tta:\n",
        "                _, _, _, probs = self.evaluate_with_tta(\n",
        "                    model, test_files, test_labels, n_aug=3\n",
        "                )\n",
        "            else:\n",
        "                model.eval()\n",
        "                probs = []\n",
        "\n",
        "                transform = T.Compose([\n",
        "                    ResizeOrPad(224),\n",
        "                    T.Resize((224, 224)),\n",
        "                    T.ToTensor(),\n",
        "                    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for img_path in test_files:\n",
        "                        image = Image.open(img_path).convert('RGB')\n",
        "                        img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "                        primary_output, _ = model(img_tensor)\n",
        "                        prob = F.softmax(primary_output, dim=1).cpu().numpy()\n",
        "                        probs.append(prob)\n",
        "\n",
        "            all_model_probs.append(np.array(probs).squeeze())\n",
        "            model_weights.append(accuracy ** 2)\n",
        "\n",
        "        model_weights = np.array(model_weights)\n",
        "        model_weights = model_weights / model_weights.sum()\n",
        "\n",
        "        final_probs = np.zeros_like(all_model_probs[0])\n",
        "        for i, probs in enumerate(all_model_probs):\n",
        "            final_probs += probs * model_weights[i]\n",
        "\n",
        "        predictions = np.argmax(final_probs, axis=1)\n",
        "        accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "        return accuracy, predictions, final_probs\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        if not PEFT_AVAILABLE:\n",
        "            self.log(\"WARNING: PEFT library not available!\")\n",
        "            self.log(\"Install with: pip install peft\")\n",
        "            self.log(\"Continuing without PEFT...\")\n",
        "\n",
        "        try:\n",
        "            train_files, train_labels, test_files, test_labels = self.collect_dataset()\n",
        "            all_files = train_files + test_files\n",
        "            all_labels = train_labels + test_labels\n",
        "\n",
        "            fold_models = self.train_kfold_ensemble(all_files, all_labels, n_splits=5)\n",
        "\n",
        "            self.log(\"\\nTraining additional models on full training set...\")\n",
        "            full_models = self.create_anatomical_peft_models()\n",
        "\n",
        "            for model_info in full_models:\n",
        "                model_name = model_info['config']['name']\n",
        "                self.log(f\"\\nTraining {model_name} on full train set\")\n",
        "\n",
        "                trained_model, accuracy = self.train_single_model(\n",
        "                    model_info['model'],\n",
        "                    train_files, train_labels,\n",
        "                    test_files, test_labels,\n",
        "                    model_name\n",
        "                )\n",
        "\n",
        "                fold_models.append({\n",
        "                    'model': trained_model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'name': f\"{model_name}_full\"\n",
        "                })\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"INDIVIDUAL MODEL RESULTS WITH TTA:\")\n",
        "\n",
        "            best_single_acc = 0\n",
        "            for model_info in fold_models:\n",
        "                tta_acc, _, _, _ = self.evaluate_with_tta(\n",
        "                    model_info['model'], test_files, test_labels, n_aug=5\n",
        "                )\n",
        "                self.log(f\"{model_info['name']}: {tta_acc:.4f} ({tta_acc*100:.2f}%)\")\n",
        "\n",
        "                if tta_acc > best_single_acc:\n",
        "                    best_single_acc = tta_acc\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"ENSEMBLE RESULTS:\")\n",
        "\n",
        "            fold_models.sort(key=lambda x: x['accuracy'], reverse=True)\n",
        "            top_models = fold_models[:7]\n",
        "\n",
        "            ensemble_acc, _, _ = self.ensemble_predict(\n",
        "                top_models, test_files, test_labels, use_tta=False\n",
        "            )\n",
        "            self.log(f\"Ensemble (no TTA): {ensemble_acc:.4f} ({ensemble_acc*100:.2f}%)\")\n",
        "\n",
        "            ensemble_tta_acc, predictions, probs = self.ensemble_predict(\n",
        "                top_models, test_files, test_labels, use_tta=True\n",
        "            )\n",
        "            self.log(f\"Ensemble with TTA: {ensemble_tta_acc:.4f} ({ensemble_tta_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*60)\n",
        "            self.log(\"DETAILED CLASSIFICATION REPORT:\")\n",
        "\n",
        "            report = classification_report(\n",
        "                test_labels, predictions,\n",
        "                target_names=self.class_names,\n",
        "                digits=4\n",
        "            )\n",
        "            self.log(report)\n",
        "\n",
        "            cm = confusion_matrix(test_labels, predictions)\n",
        "            self.log(\"\\nConfusion Matrix:\")\n",
        "            self.log(str(cm))\n",
        "\n",
        "            self.log(\"\\nPer-class Accuracy:\")\n",
        "            for i, class_name in enumerate(self.class_names):\n",
        "                class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
        "                self.log(f\" {class_name}: {class_acc:.4f} ({class_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\nAnatomical Group Analysis:\")\n",
        "            group_correct = {i: 0 for i in range(self.num_groups)}\n",
        "            group_total = {i: 0 for i in range(self.num_groups)}\n",
        "\n",
        "            for true_label, pred_label in zip(test_labels, predictions):\n",
        "                true_group = self.class_to_anatomical_group[true_label]\n",
        "                pred_group = self.class_to_anatomical_group[pred_label]\n",
        "\n",
        "                group_total[true_group] += 1\n",
        "                if true_group == pred_group:\n",
        "                    group_correct[true_group] += 1\n",
        "\n",
        "            for i, group_name in enumerate(self.anatomical_group_names):\n",
        "                if group_total[i] > 0:\n",
        "                    group_acc = group_correct[i] / group_total[i]\n",
        "                    self.log(f\" {group_name}: {group_acc:.4f} ({group_acc*100:.2f}%)\")\n",
        "\n",
        "            self.log(\"\\n\" + \"=\"*80)\n",
        "            self.log(\"FINAL RESULTS WITH ANATOMICAL GROUP AUXILIARY LOSS + PEFT:\")\n",
        "            self.log(f\"Best Single Model with TTA: {best_single_acc:.4f} ({best_single_acc*100:.2f}%)\")\n",
        "            self.log(f\"Ensemble with TTA: {ensemble_tta_acc:.4f} ({ensemble_tta_acc*100:.2f}%)\")\n",
        "\n",
        "            final_accuracy = max(best_single_acc, ensemble_tta_acc)\n",
        "\n",
        "            self.log(\"\\nSaving models...\")\n",
        "            ensemble_info = {\n",
        "                'models': [m['name'] for m in top_models],\n",
        "                'weights': [m['accuracy'] for m in top_models],\n",
        "                'final_accuracy': ensemble_tta_acc,\n",
        "                'class_names': self.class_names,\n",
        "                'anatomical_groups': self.anatomical_group_names,\n",
        "                'class_to_group_mapping': self.class_to_anatomical_group,\n",
        "                'peft_config': {\n",
        "                    'use_peft': self.use_peft,\n",
        "                    'rank': self.lora_rank,\n",
        "                    'alpha': self.lora_alpha,\n",
        "                    'peft_available': PEFT_AVAILABLE\n",
        "                }\n",
        "            }\n",
        "\n",
        "            import pickle\n",
        "            with open(self.results_dir / 'ensemble_info.pkl', 'wb') as f:\n",
        "                pickle.dump(ensemble_info, f)\n",
        "\n",
        "            for i, model_info in enumerate(top_models):\n",
        "                torch.save(\n",
        "                    model_info['model'].state_dict(),\n",
        "                    self.results_dir / f\"ensemble_model_{i}.pt\"\n",
        "                )\n",
        "\n",
        "            self.log(f\"\\nResults saved to: {self.results_dir}\")\n",
        "\n",
        "            return {\n",
        "                'final_accuracy': final_accuracy,\n",
        "                'ensemble_accuracy': ensemble_tta_acc,\n",
        "                'best_single_accuracy': best_single_acc,\n",
        "                'num_models': len(top_models)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log(f\"Error: {e}\")\n",
        "            import traceback\n",
        "            self.log(traceback.format_exc())\n",
        "            return None"
      ],
      "metadata": {
        "id": "Xyj2Ln4ZQtm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/kaggle/working/data_cifar10_style_public\"\n",
        "\n",
        "use_peft = True\n",
        "lora_rank = 16\n",
        "lora_alpha = 32\n",
        "\n",
        "classifier = EndoscopyClassifierWithPEFT(\n",
        "    data_path,\n",
        "    test_size=0.2,\n",
        "    use_peft=use_peft,\n",
        "    lora_rank=lora_rank,\n",
        "    lora_alpha=lora_alpha\n",
        ")\n",
        "\n",
        "results = classifier.run_pipeline()"
      ],
      "metadata": {
        "id": "ZZoSz8LQRvLh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}